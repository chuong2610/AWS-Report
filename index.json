[{"uri":"https://chuong2610.github.io/AWS-Report/3-eventparticipated/3.1-event1/","title":"Event 1","tags":[],"description":"","content":"Event Report: \u0026ldquo;Vietnam Cloud Day 2025: Ho Chi Minh City Connect Edition for Builders\u0026rdquo; Focus Track: GenAI \u0026amp; Data (Generative Artificial Intelligence \u0026amp; Data)\nI. PARTICIPATION OBJECTIVES Attending this event aimed to stay current with the latest AWS trends and solutions, focusing on four primary goals:\nComprehensive GenAI Strategy: Understanding how to build AI-driven software development lifecycles (AI-DLC) and explore cutting-edge GenAI strategies Enterprise Security: Deep dive into securing GenAI and AI Agents to ensure data protection Data Foundation: Learning to construct a Unified Data Foundation optimized for Analytics and AI workloads Expert Networking: Direct engagement with AWS engineers and specialists Speaker Lineup:\nAWS Team: Jun Kai Loke (AI/ML Specialist), Kien Nguyen, Tamelly Lim, Binh Tran, Taiki Dang (Solutions Architects), Michael Armentano (Principal WW GTM Specialist).\nII. CORE TECHNICAL CONTENT 1. Unified Data Platform For AI to function effectively, data must flow seamlessly. AWS emphasizes the Zero-ETL model and breaking down data silos:\nEnd-to-End Workflow: From Ingestion $\\rightarrow$ Storage $\\rightarrow$ Processing $\\rightarrow$ Access $\\rightarrow$ Governance Service Ecosystem: Tight integration among Amazon S3, Glue, Redshift, Lake Formation, and OpenSearch Self-Service Philosophy: Empowering project teams to leverage data independently while maintaining compliance standards 2. GenAI Strategy \u0026amp; Amazon Bedrock Amazon Bedrock: Central platform for Foundation Model selection, RAG (Retrieval-Augmented Generation) deployment, and cost/latency optimization AgentCore \u0026amp; Amazon Nova: Strong support for modern Agent frameworks like CrewAI, LangGraph, and LlamaIndex, enabling complex automation workflows 3. Multi-Layered Security for GenAI Security extends beyond infrastructure through a \u0026ldquo;Defense in Depth\u0026rdquo; model:\nThree Security Layers: Infrastructure $\\rightarrow$ Model $\\rightarrow$ Application Five Core Pillars: Compliance, Privacy, Controls, Risk Management, and Resilience Practical Tools: Bedrock Guardrails for content filtering and OpenTelemetry for observability 4. AI-Driven Development Lifecycle (AI-DLC) This represents a fundamental shift in software development thinking:\nEvolution: Progressing from AI-Assisted (AI helps code) $\\rightarrow$ AI-Driven (AI leads) $\\rightarrow$ AI-Managed (AI manages operations) Implementation: Integrating AI across all phases: IaC (Infrastructure as Code), automated testing, to risk management 5. Amazon SageMaker ‚Äì Unified Studio Consolidated environment for Data, Analytics, and AI with Lakehouse architecture support Comprehensive MLOps integration (Pipelines, Registry, Monitoring) accelerating GenAI application deployment III. LESSONS LEARNED \u0026amp; KEY INSIGHTS From the above content, I extracted three fundamental lessons for project development:\nDesign Thinking: Build Data \u0026amp; AI systems with \u0026ldquo;End-to-End\u0026rdquo; thinking from the start to avoid fragmentation Governance principles must align with self-service capabilities Technical Architecture: Maximize Zero-ETL usage (S3 $\\leftrightarrow$ Redshift/Aurora/DynamoDB integration) to minimize data pipeline overhead Utilize AI Agents for workflow automation rather than treating AI as just a chatbot tool Reliability and Accuracy: To reduce AI hallucinations, combine: Prompt Engineering + RAG + Fine-tuning Standard RAG workflow: $Input \\rightarrow Embedding \\rightarrow Context \\rightarrow LLM \\rightarrow Output$ IV. WORK APPLICATION PLAN Based on the acquired knowledge, I propose specific application directions:\n1. For Current Projects Features: Experiment with integrating AI Agents into Customer Support workflows and authentication processes Safety: Apply Bedrock Guardrails and validation layers to prevent AI from generating sensitive or misleading content 2. For Development Processes (Team \u0026amp; Learning) AI-DLC Model: Clear task division: AI handles code generation and documentation; humans focus on Review and Approval Infrastructure: Carefully evaluate Serverless (AWS Lambda) for short-lived tasks versus Containers (ECS/Fargate) for long-running/complex workloads 3. Personal Direction (Intern/Developer Role) Business-First: Always ask \u0026ldquo;What\u0026rsquo;s the business value?\u0026rdquo; before writing code or gathering requirements. Technology must serve business objectives Data Mindset: Recognize that a clean, structured data foundation is a prerequisite for effective GenAI performance Event Experience Attending the ‚ÄúGenAI-powered App-DB Modernization‚Äù workshop was extremely valuable, giving me a comprehensive view of modernizing applications and databases using advanced methods and tools. Key experiences included:\nLearning from highly skilled speakers Experts from AWS and major tech organizations shared best practices in modern application design. Through real-world case studies, I gained a deeper understanding of applying DDD and Event-Driven Architecture to large projects. Hands-on technical exposure Participating in event storming sessions helped me visualize how to model business processes into domain events. Learned how to split microservices and define bounded contexts to manage large-system complexity. Understood trade-offs between synchronous and asynchronous communication and integration patterns like pub/sub, point-to-point, streaming. Leveraging modern tools Explored Amazon Q Developer, an AI tool for SDLC support from planning to maintenance. Learned to automate code transformation and pilot serverless with AWS Lambda to improve productivity. Networking and discussions The workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned Applying DDD and event-driven patterns reduces coupling while improving scalability and resilience. Modernization requires a phased approach with ROI measurement; rushing the process can be risky. AI tools like Amazon Q Developer can significantly boost productivity when integrated into the current workflow. Overall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Tr·∫ßn Ng·ªçc Ch∆∞∆°ng\nPhone Number: 0397812503\nEmail: chuongtnse181579@fpt.edu.vn\nUniversity: FPT University\nMajor: Software Engineer\nClass: SE181579\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 09/08/2025 to 12/12/2025\nReport Content Worklog Proposal Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":"Week 1 Objectives: Connect and get acquainted with members of First Cloud Journey. Understand the core AWS foundational services, including Account, Billing, IAM, VPC, and EC2. Learn how to manage costs and access permissions. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Get acquainted with FCJ members - Read and take note of internship unit rules and regulations - Explore AWS Services: Get a high-level overview of the main service categories. 09/08/2025 09/08/2025 3 - Learn about Creating Your First AWS Account - Learn about Managing Costs with AWS Budgets - Learn about Getting Help with AWS Support - Practice: + Create AWS Free Tier account + Set up a budget alert + \u0026hellip; 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn about Access Management with AWS Identity and Access Management (IAM) - Practice: + Create an IAM User, Group + Attach policies for access 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn about Networking Essentials with Amazon Virtual Private Cloud (VPC) - Learn about Compute Essentials with Amazon Elastic Compute Cloud (EC2) - Practice: + Set up a custom VPC\n+ Launch an EC2 instance into the VPC 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn about Instance Profiling with IAM Roles for EC2 - Practice: + Create an IAM Role for EC2 + Attach the Role to an existing EC2 instance 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ 7 - Week Review and Documentation - Practice: + Review all services learned this week + Document key learnings and challenges 09/13/2025 09/13/2025 https://cloudjourney.awsstudygroup.com/ CN - Self-study and Practice + Review and practice AWS fundamentals + Prepare for next week\u0026rsquo;s topics 09/14/2025 09/14/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Understood the foundational AWS service groups:\nCompute (Amazon EC2) Networking (Amazon VPC) Identity \u0026amp; Access Management (IAM) Billing \u0026amp; Cost Management (AWS Budgets) \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nPracticed with Identity and Access Management (IAM), including:\nCreating Users and Groups Attaching Policies Creating IAM Roles for EC2 \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/","title":"Worklog","tags":[],"description":"","content":"This worklog documents my 12-week AWS learning journey during the internship program, spanning from September 8, 2025 to November 30, 2025. Throughout this period, I systematically explored AWS services, built hands-on projects, and developed practical cloud engineering skills.\nProgram Overview The program was completed over 12 weeks with structured weekly objectives covering fundamental to advanced AWS topics. Each week included practical labs, hands-on exercises, and real-world implementation scenarios.\nWeekly Learning Path Week 1: AWS Fundamentals \u0026amp; Core Services - Introduction to cloud computing, AWS Global Infrastructure, IAM basics, VPC networking, and EC2 instance management\nWeek 2: Compute \u0026amp; Storage Deep Dive - Advanced EC2 configurations, EBS volumes, AWS Cloud9 IDE, Amazon S3 storage, and AWS Lightsail for simplified deployments\nWeek 3: Managed Databases \u0026amp; High Availability - Amazon RDS for relational databases, DynamoDB for NoSQL, ElastiCache for in-memory caching, and designing highly available architectures\nWeek 4: Scalability \u0026amp; Content Delivery - Auto Scaling Groups, CloudWatch monitoring and alarms, Route 53 DNS management, and CloudFront CDN for global content delivery\nWeek 5: Infrastructure as Code \u0026amp; Automation - AWS Systems Manager for operational tasks, CloudFormation for infrastructure provisioning, AWS CDK for programmatic infrastructure, and ABAC authorization\nWeek 6: Security \u0026amp; Identity Management - AWS WAF for web application protection, KMS for encryption key management, Secrets Manager, Amazon GuardDuty threat detection, and Amazon Cognito for user authentication\nWeek 7: Migration \u0026amp; Messaging Services - VM migration strategies, AWS Database Migration Service, disaster recovery planning, Amazon SQS for queuing, and SNS for notifications\nWeek 8: Cost Optimization \u0026amp; Networking - AWS cost management best practices, FinOps principles, AWS Transit Gateway for network connectivity, and resource optimization strategies\nWeek 9: Containerization \u0026amp; Orchestration - Docker containerization fundamentals, Amazon ECS for container management, AWS Fargate for serverless containers, and Amazon EKS for Kubernetes\nWeek 10: Serverless Architecture - AWS Lambda functions, serverless computing patterns, Amazon API Gateway for RESTful APIs, and AWS Step Functions for workflow orchestration\nWeek 11: Microservices \u0026amp; CI/CD - Microservices architecture patterns, continuous integration and deployment pipelines, DevOps practices, and AWS Elastic Beanstalk for application deployment\nWeek 12: Data Analytics \u0026amp; Machine Learning - Data lake architecture with AWS Lake Formation, AWS Glue for ETL, Amazon Athena for SQL queries, and Amazon SageMaker for machine learning model development\n"},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.1-workshop-overview/","title":"Workshop Overview","tags":[],"description":"","content":"Introduction to EV Rental AI Agent What is an AI Agent? An AI Agent is an intelligent system that can:\nUnderstand natural language queries Automatically select and execute appropriate tools/functions Make decisions based on context Provide structured responses with data Unlike traditional chatbots with fixed responses, AI Agents can reason and take actions dynamically.\nSystem Architecture Our EV Rental AI Agent uses a multi-layered architecture:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ User Interface ‚îÇ ‚Üê React Frontend (Chat UI) ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ HTTP/REST ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ FastAPI Server ‚îÇ ‚Üê Backend Orchestrator ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚Üì ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ Strands ‚îÇ ‚îÇ PostgreSQL ‚îÇ ‚îÇ Agent SDK‚îÇ ‚îÇ (History) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí AWS Bedrock (Claude 3.5 Sonnet) ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Knowledge Base (Policies/FAQ) ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Backend API (Vehicles/Stations) Key Components Component Technology Purpose AI Model AWS Bedrock - Claude 3.5 Sonnet Natural language understanding \u0026amp; generation Agent Framework Strands Agent SDK Automatic tool selection \u0026amp; orchestration Backend API FastAPI (Python) REST API server for agent logic Database PostgreSQL Store chat history \u0026amp; sessions Frontend React + Chakra UI Interactive chat interface Knowledge Base AWS Bedrock KB Document retrieval (policies, FAQ) Core Features 1. Knowledge Base Search Agent searches through uploaded documents to answer questions about:\nRental policies Pricing information Booking procedures Terms and conditions Example Query:\n\u0026ldquo;Ch√≠nh s√°ch thu√™ xe c·ªßa b·∫°n l√† g√¨?\u0026rdquo;\nAgent Response:\n## üìã VinFast Rental Policies ### üìÑ Required Documents: - ‚úÖ Valid ID/Passport - ‚úÖ Driver\u0026#39;s License (Class B1+) - ‚úÖ Proof of Residence ### üí∞ Pricing: - **VF8**: 1,500,000 VNƒê/day - **VF9**: 2,000,000 VNƒê/day - **Deposit**: 10,000,000 VNƒê 2. Vehicle Search Agent queries the backend API to find available vehicles based on:\nLocation (city) Date range Vehicle model/type Response Format: Interactive vehicle cards with specs\n3. Charging Station Finder Agent retrieves nearby charging stations with:\nAddress and status Available chargers Distance (if location provided) Response Format: Station cards with real-time availability\nWorkshop Objectives By the end of this workshop, you will be able to:\n‚úÖ Configure AWS Bedrock - Enable Claude models and create a Knowledge Base ‚úÖ Build an AI Agent Backend - Use Strands SDK to orchestrate multiple tools ‚úÖ Deploy a Chat Interface - Create a responsive React chat UI ‚úÖ Test End-to-End - Interact with the AI agent and verify all functionalities Technology Stack AWS Services:\nAWS Bedrock (Claude 3.5 Sonnet v2) AWS Bedrock Knowledge Bases AWS S3 (for document storage) IAM (for access management) Backend:\nPython 3.11+ FastAPI Strands Agent SDK PostgreSQL SQLAlchemy Frontend:\nReact 18 Chakra UI Axios React Markdown Workshop Flow Step 1: Prerequisites ‚Üì Step 2: Setup AWS Bedrock \u0026amp; Knowledge Base ‚Üì Step 3: Deploy Backend API (FastAPI) ‚Üì Step 4: Deploy Frontend (React) ‚Üì Step 5: Test the AI Agent ‚Üì Step 6: Cleanup Resources Next: Let\u0026rsquo;s move to Prerequisites to prepare your environment.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/3-eventparticipated/3.2-event2/","title":"Event 2","tags":[],"description":"","content":"Comprehensive Report: AWS Cloud Mastery Series #1 Focus: GENERATIVE AI, RAG \u0026amp; AWS AGENTIC AI\n1. Primary Event Objectives The event focused on equipping comprehensive knowledge to build modern AI applications on the AWS platform:\nOptimize Interactions: Enhance Prompt Engineering skills to precisely control AI models. Rapid Application: Utilize AWS Pretrained AI Services to integrate artificial intelligence without training models from scratch. Master Your Data: Implement RAG (Retrieval-Augmented Generation) architecture to update AI with proprietary knowledge and eliminate hallucinations. Transition to Agentic AI: Learn how to move AI Agents from proof-of-concept (POC) to production using Amazon Bedrock AgentCore. Real-time Communication: Explore the Pipecat Framework to create ultra-low latency voice virtual assistants. 2. Featured Speakers L√¢m Tu·∫•n Ki·ªát (Sr DevOps Engineer - FPT Software): Shared in-depth insights on system operations. Danh Ho√†ng Hi·∫øu Ngh·ªã (AI Engineer - Renova Cloud): Expert on AI solutions and models. ƒêinh L√™ Ho√†ng Anh (Cloud Engineer Trainee - First Cloud AI Journey): Representative perspective of those beginning their Cloud AI journey. 3. In-Depth Content 3.1. Prompt Engineering \u0026amp; Foundation Models: Solid Foundation The event emphasized the principle \u0026ldquo;Good input creates good output.\u0026rdquo; To work effectively with Foundation Models on Bedrock, mastering these techniques is essential:\nZero-shot / Few-shot Prompting: Techniques for providing context or sample examples to guide AI toward correctly formatted desired results. Chain of Thought (CoT): Technique requiring AI to \u0026ldquo;think step-by-step,\u0026rdquo; helping solve complex logical reasoning problems and minimize errors. 3.2. AWS AI Services Ecosystem (Pretrained) API solutions enabling developers to quickly integrate intelligent features into applications:\nVision: Amazon Rekognition (Image/video analysis, content moderation). Language: Amazon Translate (Translation), Comprehend (Semantic analysis), Textract (Document text extraction). Audio: Amazon Polly (Text-to-Speech) and Transcribe (Speech-to-Text). 3.3. RAG - Solution for Enterprise Data RAG is the key to enabling AI to understand internal data without expensive fine-tuning:\nMechanism: Uses Amazon Titan Text Embeddings V2 for data vectorization, enabling semantic search. Knowledge Bases for Amazon Bedrock: Fully managed service handling the complete RAG workflow: from document chunking, vector storage, retrieval to answer generation. 3.4. Advancing to Agentic AI (Task-Oriented AI) The GenAI trend is strongly shifting from \u0026ldquo;Question-Answer\u0026rdquo; to \u0026ldquo;Action\u0026rdquo;:\nHierarchy: From Assistant (single tasks) ‚Üí Agents (goal-oriented, tool-using) ‚Üí Agentic Systems (multi-agent, autonomous). \u0026ldquo;Prototype to Production\u0026rdquo; Challenge: Many Agent projects fail in production due to processing speed issues, data security risks, and poor memory/context maintenance. 3.5. Amazon Bedrock AgentCore: Infrastructure for AI Agents AgentCore solves critical challenges enabling enterprises to confidently deploy Agents:\nControl: Strict identity and permission management. Execution Capability: Integrated Code Interpreter (secure Python sandbox) for precise computation. Observability: Enables tracking Agent reasoning flows for debugging and optimization. Memory: Maintains context across extended conversation sessions. 3.6. Pipecat Framework: The Future of Voice AI Open-source solution for real-time multimodal communication applications:\nAdvantages: Extremely low latency creating natural conversation experiences. Pipeline Process: Parallel processing of WebRTC ‚Üí STT ‚Üí LLM ‚Üí TTS streams ensuring instant responses. 4. Personal Lessons and Reflections Through this workshop, I systematized the technology development roadmap and extracted key insights:\nAgentic AI Thinking: AI is no longer a passive lookup tool but has become a \u0026ldquo;digital employee\u0026rdquo; capable of planning and taking action. Bedrock AgentCore is the crucial piece to realize this vision. Overcoming Production Barriers: Insights about the \u0026ldquo;deep gap\u0026rdquo; between demos and reality were highly valuable. AWS\u0026rsquo;s security and monitoring features address concerns about safety when empowering AI. Potential of Touchless Communication: Pipecat opens significant opportunities for practical applications like AI Call Centers, Virtual Training, or Automated Interviews thanks to impressive real-time response capabilities. 5. Conclusion The \u0026ldquo;Generative AI \u0026amp; Agentic AI on AWS\u0026rdquo; event painted a clear picture:\nPresent: Optimizing RAG and Prompt Engineering. Future: Transitioning to autonomous Agent systems. With support from the AWS ecosystem (Bedrock, AgentCore) and the Open Source community (Pipecat), technical barriers have been lowered, creating momentum for an explosion of innovative business solutions.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.2-prerequiste/","title":"Prerequisites","tags":[],"description":"","content":"Prerequisites for EV Rental AI Agent Workshop Before starting this workshop, ensure you have the following requirements ready:\n1. AWS Account You need an AWS Account with appropriate permissions to:\nAccess AWS Bedrock service Create and manage IAM users Create S3 buckets (for Knowledge Base) Create Knowledge Bases Note: Bedrock is available in specific regions. Recommended regions:\nus-west-2 (Oregon) us-east-1 (N. Virginia) ap-southeast-1 (Singapore) 2. IAM User with Bedrock Permissions You need to create an IAM User with AWS Bedrock access for your application.\nStep 1: Create IAM User\nGo to AWS Console ‚Üí IAM ‚Üí Users ‚Üí Create User User name: bedrock-agent-user ‚úÖ Check: Provide user access to the AWS Management Console (optional) ‚úÖ Select: I want to create an IAM user Click Next Step 2: Attach Permissions\nSelect: Attach policies directly Search and select these policies: ‚úÖ AmazonBedrockFullAccess - Full access to Bedrock models and Knowledge Bases ‚úÖ (Optional) AmazonS3ReadOnlyAccess - If using Knowledge Base with S3 Click Next ‚Üí Create User Step 3: Create Access Keys\nClick on the newly created user: bedrock-agent-user Go to Security credentials tab Scroll down to Access keys ‚Üí Click Create access key Select use case: Application running outside AWS Click Next ‚Üí Create access key ‚ö†Ô∏è IMPORTANT: Copy and save: Access Key ID (example: AKIAIOSFODNN7EXAMPLE) Secret Access Key (shown only once, example: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY) Click Done ‚ö†Ô∏è Security Note:\n# Save to .env file (DO NOT commit to Git) AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID_HERE AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY_HERE AWS_REGION=us-west-2 3. Development Environment 3.1. Python Environment Python 3.11 or higher Package manager: pip Verify installation:\npython --version # Expected: Python 3.11.x or higher pip --version 3.2. Node.js Environment Node.js 18+ and npm Required for React frontend Verify installation:\nnode --version # Expected: v18.x.x or higher npm --version 3.3. PostgreSQL Database PostgreSQL 14+ installed locally or use Docker Option 1: Install locally\nDownload from: https://www.postgresql.org/download/ Create database: ev_rental_db Option 2: Use Docker\ndocker run -d \\ --name postgres-ev \\ -e POSTGRES_PASSWORD=password \\ -e POSTGRES_DB=ev_rental_db \\ -p 5432:5432 \\ postgres:14 Verify PostgreSQL:\n# Check PostgreSQL is running psql --version # Connect to database psql -U postgres -d ev_rental_db 4. Code Editor \u0026amp; Tools VS Code or your preferred IDE Git for cloning repositories Postman or cURL for API testing (optional) Install VS Code:\nDownload from: https://code.visualstudio.com/ Install Git:\n# macOS brew install git # Windows # Download from: https://git-scm.com/download/win # Verify git --version 5. AWS CLI (Optional) Install AWS CLI to interact with AWS services from command line:\n# macOS/Linux curl \u0026#34;https://awscli.amazonaws.com/AWSCLIV2.pkg\u0026#34; -o \u0026#34;AWSCLIV2.pkg\u0026#34; sudo installer -pkg AWSCLIV2.pkg -target / # Windows # Download from: https://awscli.amazonaws.com/AWSCLIV2.msi # Verify aws --version Configure AWS CLI:\naws configure # Enter your Access Key ID: AKIA5GPEMGJZK6E7PMEB # Enter your Secret Access Key: (paste your secret key) # Default region name: us-west-2 # Default output format: json Test AWS CLI:\n# List available Bedrock models aws bedrock list-foundation-models --region us-west-2 # Check your identity aws sts get-caller-identity Prerequisites Checklist Before proceeding to the next step, ensure you have:\n‚úÖ AWS Account with Bedrock access in supported region ‚úÖ IAM User created with AmazonBedrockFullAccess policy ‚úÖ Access Key ID and Secret Access Key saved securely ‚úÖ Python 3.11+ installed and verified ‚úÖ Node.js 18+ and npm installed and verified ‚úÖ PostgreSQL 14+ database running ‚úÖ Code editor (VS Code recommended) installed ‚úÖ Git installed and configured ‚úÖ (Optional) AWS CLI installed and configured Estimated Costs This workshop uses the following AWS services:\nService Estimated Cost Notes AWS Bedrock - Claude 3.5 Sonnet ~$0.50 - $2.00 Pay per API call (input/output tokens) AWS Bedrock - Knowledge Base ~$0.10 - $0.50 Vector storage + retrieval S3 Storage ~$0.02 Minimal for documents Data Transfer ~$0.05 Usually within free tier Total ~$0.67 - $2.57 For the entire workshop üí° Tip: Remember to clean up resources after the workshop to avoid ongoing charges!\nNext: Proceed to Setup AWS Bedrock to enable models and create Knowledge Base.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/2-proposal/","title":"Proposal","tags":[],"description":"","content":"The EV Station-based Rental System Electric Vehicle Rental and Return Software at Fixed Stations ‚Äì A Green Mobility Solution for Smart Cities üìÑ View Full Proposal Document\n1. Executive Summary The EV Station-based Rental System is developed to provide an all-in-one platform for electric vehicle rental and charging management. It integrates real-time rental, payment, and charging station access through a unified cloud-native solution. The system features a React Native mobile app and a Spring Boot backend deployed on AWS ECS Fargate, with PostgreSQL (RDS) and Redis (ElastiCache) for data and caching. User authentication is managed via Amazon Cognito, and global delivery is optimized using CloudFront. Designed under the AWS Well-Architected Framework, the platform ensures scalability, high availability, and security while maintaining cost efficiency.\n2. Problem Statement What‚Äôs the Problem? Current electric vehicle (EV) rental services are fragmented, requiring users to switch between multiple apps to locate, book, and manage rentals at fixed points. This creates inconvenience, slow performance, and unreliable experiences ‚Äî users often arrive at ‚Äúunavailable‚Äù or ‚Äúoffline‚Äù rental points, leading to frustration and loss of trust.\nFor vehicle owners and operators, manual fleet management, booking coordination, and maintenance tracking result in operational inefficiencies and lost revenue. Currently, there is no unified, real-time platform connecting renters, vehicle owners, and rental point operators.\nThe Solution The EV Station-based Rental System consolidates EV rental and return at fixed points into a single, cloud-native platform. Built with React Native for mobile and Spring Boot for backend, the system delivers real-time booking, vehicle tracking, and payment integration.\nKey AWS services include ECS Fargate for compute, RDS PostgreSQL for data storage, ElastiCache for low-latency performance, API Gateway and Cognito for secure access, and CloudFront for global content delivery. The platform supports both fleet-based and peer-to-peer (P2P) vehicle registration, providing a centralized interface for users and operators to manage rentals efficiently, securely, and at scale.\nBenefits and Return on Investment The platform eliminates manual coordination and fragmented applications, offering a unified, automated experience for renters and fleet owners. Real-time data ensures reliability and transparency regarding vehicle availability and rental point status.\nDesigned under the AWS Well-Architected Framework, the system minimizes operational costs with a serverless, pay-per-use model while maintaining scalability and 99.99% uptime. Within 1 months, the platform is projected to reach 1,000+ monthly active users, onboard 200+ rental points, and deliver significant time, cost, and operational efficiencies for both users and operators.\n3. Solution Architecture The VoltGo platform is built on a secure, scalable, and fully managed AWS serverless architecture. Backend services are deployed on Amazon ECS Fargate with container images stored in Amazon ECR. The system uses Aurora PostgreSQL Serverless v2 for the main relational database and ElastiCache Serverless (Valkey/Redis) for low-latency caching and session management. All services operate within private subnets across multiple Availability Zones and are securely exposed through Amazon API Gateway integrated with Application Load Balancer via AWS PrivateLink. User authentication is handled by Amazon Cognito with JWT and MFA support. The frontend is hosted on Amazon S3 and delivered globally through Amazon CloudFront with AWS WAF and ACM SSL/TLS protection. AI-powered features are implemented using Amazon Bedrock integrated via AWS Lambda, while Amazon Location Service provides map and nearby station search functionality. Monitoring and logging are centralized in Amazon CloudWatch, and the entire infrastructure is provisioned using Terraform for automated and consistent deployments.\nAWS Services Used Amazon ECS Fargate: Serverless container orchestration for backend microservices. Amazon PostgreSQL: Relational database. Amazon ElastiCache Serverless (Valkey): In-memory caching for low-latency data access. Amazon API Gateway: Secure REST API entry point integrated via PrivateLink. Amazon Cognito: User authentication and authorization with JWT and MFA. Amazon CloudFront + S3: Global content delivery and static hosting with WAF protection. Amazon CloudWatch: Unified monitoring, logging, and alerting for all services. Amazon ACM: Edge-level security and SSL/TLS certificate management. Amazon Application Load Balancer: Route traffic forward to target group Amazon Location Service: Providing map and places (index) for frontend allow user search and check station nearly. Amazon Bedrock: Handling chatting support user for QA and find nearby station base on user\u0026rsquo;s location Amazon EC2: Bastion Server connect RDS to config extension and running script Amazon Lambda: Bridge connect with Bedrock to handle api in QA from user Amazon ECR: Repository store image for ecs task Component Design Frontend:React web application hosted on Amazon S3 and delivered via CloudFront, secured ACM SSL/TLS certificates. API Layer: Amazon API Gateway provides the public API endpoint. Compute Layer: Amazon ECS Fargate runs containerized across multiple Availability Zones, scaling automatically based on CPU and memory utilization. Database Layer:Amazon PostgreSQL stores relational data for high availability and automated scaling. Caching Layer: Amazon ElastiCache Serverless (Redis) caches session and booking data to reduce database load and improve response time. Authentication: Amazon Cognito handles user registration, login, and JWT-based authorization with optional MFA support. Storage: Amazon S3 manages static assets and user uploads, accessible only through CloudFront via Origin Access Control (OAC). Monitoring \u0026amp; Security: Amazon CloudWatch tracks logs and performance metrics, while AWS Secrets Manager securely stores credentials with automatic rotation. 4. Technical Implementation Implementation Phases This project has two main parts‚Äîdeveloping the backend locally and deploying it to the AWS cloud‚Äîeach following four key phases:\n1.Build and Design Architecture: Develop and test backend services locally using Docker Compose, PostgreSQL, and Redis. Design the AWS serverless architecture including ECS Fargate, Aurora Serverless, ElastiCache, and API Gateway with PrivateLink connections. (Pre-deployment phase) 2.Estimate Cost and Validate Feasibility: Use AWS Pricing Calculator to estimate the monthly cost of ECS tasks, Aurora capacity units, and CloudFront bandwidth. Adjust design decisions to ensure cost-effectiveness and smooth migration. 3.Configure and Deploy Infrastructure: Build and deploy cloud infrastructure using Terraform for IaC. Configure VPC, ECS, Aurora, ElastiCache, Cognito, and CloudFront. Validate IAM roles, networking, and private-only access via VPC Endpoints. 4.Test, Optimize, and Release: Deploy Dockerized services to ECS Fargate, test API Gateway ‚Üí PrivateLink ‚Üí NLB ‚Üí ECS flow, and verify database connections. Enable CloudWatch monitoring, auto-scaling, and WAF protection. Optimize scaling thresholds and document final architecture. Technical Requirements\nBackend Services: Node.js or Spring Boot microservices for Auth, Booking, and Payment, containerized with Docker and deployed to ECS Fargate (2‚Äì10 tasks, auto-scaling). Database Layer: Amazon Aurora PostgreSQL Serverless v2 with writer and reader instances, supporting automatic scaling and multi-AZ high availability. Caching Layer: Amazon ElastiCache Serverless (Redis 7.1) for session caching and frequently accessed data. Authentication: Amazon Cognito manages user registration, JWT-based authentication, and optional MFA, integrated with API Gateway. Storage \u0026amp; Content Delivery: Frontend hosted on Amazon S3 and distributed via CloudFront, protected by AWS WAF and ACM SSL/TLS certificates. Secrets \u0026amp; Monitoring: AWS Secrets Manager for storing credentials (DB, Redis, JWT keys) with 30-day rotation. Amazon CloudWatch for logging, metrics, and scaling alarms. 5. Timeline \u0026amp; Milestones Project Timeline\nPhase 1: Foundation \u0026amp; Design (Weeks 1-2) Week 1: Finalize MVP scope (P0 User Stories), define user flows, and approve the AWS architecture. Week 2: FE Lead finalizes UI/UX mockups. Backend provisions core AWS (VPC, S3, ECR, Aurora). Phase 2: Core MVP Development (Weeks 3-8) Weeks 3-4: Backend builds User Auth (Cognito) \u0026amp; core APIs (API Gateway, ECS). Weeks 5-6: All teams (FE/BE/Mobile) build core screens (Login, Search, Details) and the Booking Engine APIs. Weeks 7-8: Integration of KYC flow (Lambda, Textract, Rekognition) and Payment Gateway integration. Phase 3: Testing \u0026amp; UAT (Weeks 9-10) Week 9: Full End-to-End (E2E) testing. QA is performed by the 5-person dev team, as no dedicated QA is allocated. Week 10: Stakeholder User Acceptance Testing (UAT) and final critical bug fixing. Phase 4: Launch (Week 11) Week 11: Production deployment, Go-live, and intensive Hypercare monitoring via CloudWatch. 6. Budget Estimation This budget estimate is based on the provided AWS architecture diagram and the \u0026ldquo;cheapest possible\u0026rdquo; MVP launch strategy, maximizing Free Tier usage.\nInfrastructure Costs AWS Services (Monthly Estimate): Amazon Route 53: $0.50/month (1 hosted zone). AWS WAF: $6.00/month (1 WebACL + 1 Rule + minimal requests). AWS S3 Standard: $0.00/month (Stays within 5GB Always Free tier). Amazon CloudFront: $0.00/month (Stays within 1TB/10M request Always Free tier). AWS Cognito: $0.00/month (Stays within 10,000 MAU free tier). Amazon API Gateway: $0.00/month (Stays within 1M request 12-month free tier). AWS Lambda: $0.00/month (Stays within 1M request Always Free tier). Amazon Textract/Rekognition: $0.00/month (Stays within 12-month free tier for KYC). Application Load Balancer: $17.52/month (1 ALB, minimal processing). VPC Endpoint (PrivateLink): $7.30/month (1 Endpoint, 1 AZ, 1GB data). Amazon ECS on Fargate: ~$20.00/month (Assumes 2 minimal 24/7 containers, e.g., 0.25 vCPU/0.5GB RAM). Amazon Aurora Serverless v2: ~$25.00/month (Minimal ACUs, configured to scale to near-zero). Amazon ElastiCache Serverless: ~$10.00/month (Minimal usage). Amazon CloudWatch: $0.00/month (Stays within 5GB log Always Free tier). Amazon ECR: ~$0.10/month (Minimal storage over 500MB free tier). Total: ~$86.42/month, ~$1,037.04/12 months\n7. Risk Assessment Risk Matrix System Downtime: High impact, medium probability. Data Sync Errors (Between Stations \u0026amp; Server): Medium impact, high probability. OCR Verification Failure: Medium impact, medium probability. Vehicle Shortage or Low Battery at Stations: High impact, high probability. Operational Mistakes by Staff: Medium impact, medium probability. Cost Overruns: Medium impact, low probability. Mitigation Strategies System: Use load-balanced cloud servers with auto-scaling and failover backup. Data Sync: Implement offline caching and periodic background synchronization. OCR Verification: Combine AI-based ID recognition with manual approval option. Vehicle Management: Real-time tracking of battery and vehicle status; predictive restocking via analytics. Staff Operations: Provide training and digital checklists to reduce human error. Cost: Set up cloud cost monitoring and optimization alerts. Contingency Plans Enable offline mode for station staff when Internet is unavailable. Activate backup servers in case of major downtime. Provide manual check-in/out workflow for rentals during system outages. Deploy mobile maintenance team to handle vehicle or battery issues at stations. Suspend or limit reservations dynamically if vehicle supply falls below safe threshold. 8. Expected Outcomes Technical Improvements: Real-time monitoring of all EV stations and rental status. Automated verification and e-contract signing replace manual paperwork. Centralized dashboard for admins to manage fleet, customers, and staff. System scalable to 20+ rental stations in the next deployment phase. Long-term Value Establishes a reliable EV mobility infrastructure for urban areas. Builds data foundation for future AI-powered demand forecasting. Enables integration with smart city and green transportation networks. Serves as a reusable platform for expanding to nationwide EV-sharing projects. Short to Medium-term Benefits Faster customer onboarding (from 15 mins ‚Üí \u0026lt;5 mins). Increased fleet utilization rate by 30% through data-driven scheduling. Improved accuracy of rental records and payment reconciliation. Enhanced user satisfaction via seamless booking and transparent billing. "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Master Amazon EC2 (Elastic Compute Cloud) fundamentals and instance management Understand block storage with Amazon EBS and Windows workloads on AWS Learn cloud-based development with AWS Cloud9 Deep dive into Amazon S3 object storage and security best practices Explore simplified compute solutions with Amazon Lightsail and container deployment Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Compute Essentials with Amazon EC2 - Practice: + Analyze instance type families (T3, C5, R5) + Launch EC2 instances with Amazon Linux 2023 + Configure SSH access and manage Key Pairs 09/15/2025 09/15/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn about Elastic Block Store (EBS) - Learn Windows Workloads on AWS - Practice: + Create and attach EBS volumes (gp3) + Deploy Windows Server 2022 with IIS + Create EBS Snapshots for backup 09/16/2025 09/16/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn AWS Cloud9 Development Environment - Practice: + Set up Cloud9 IDE + Utilize pre-installed AWS CLI, SAM, and Docker + Practice remote code editing via browser 09/17/2025 09/17/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn S3 Fundamentals - Object Storage - Practice: + Create S3 buckets and upload objects + Configure Static Website Hosting + Write Bucket Policies for public access control 09/18/2025 09/18/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Advanced S3 Features and Security Best Practices - Practice: + Configure Storage Classes (Standard, IA, Glacier) + Set up Lifecycle Policies + Enable Versioning and Default Encryption (SSE-S3) + Configure Block Public Access 09/19/2025 09/19/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn Amazon Lightsail Simplified Compute - Practice: + Deploy WordPress using Lightsail Blueprint + Compare Lightsail vs EC2 (cost and features) + Understand LAMP stack deployment 09/20/2025 09/20/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn Container Deployment with Amazon Lightsail Containers - Practice: + Build Docker images for Node.js application + Deploy containerized app to Lightsail Container Service + Understand container basics before ECS/EKS 09/21/2025 09/21/2025 https://cloudjourney.awsstudygroup.com/ Week 2 Achievements: Mastered Amazon EC2 Compute Service:\nUnderstood instance type families: T3 (Burstable), C5 (Compute Optimized), R5 (Memory Optimized) Successfully launched EC2 instances with Amazon Linux 2023 AMI Configured secure SSH access using Key Pairs (.pem files) Managed instance lifecycle (Start, Stop, Terminate) Practiced Block Storage with Amazon EBS:\nCreated and attached EBS volumes (gp3 type) to running EC2 instances Performed mount operations on Linux instances Created EBS Snapshots for backup (incremental backup mechanism) Understood EBS persistence independent of EC2 lifecycle Deployed Windows Workloads on AWS:\nLaunched Windows Server 2022 instances Connected via Remote Desktop Protocol (RDP) Installed and configured IIS Web Server on Windows Set up Cloud-based Development Environment:\nConfigured AWS Cloud9 IDE in browser Utilized pre-installed tools: AWS CLI, SAM, Docker Experienced remote code editing without opening SSH ports publicly Eliminated \u0026ldquo;works on my machine\u0026rdquo; syndrome Deep Understanding of Amazon S3 Object Storage:\nCreated S3 buckets and uploaded various media files Configured Static Website Hosting for HTML/CSS/JS websites Wrote JSON Bucket Policies for granular access control (s3:GetObject) Implemented S3 Security Best Practices: Enabled Block Public Access at account level Activated Versioning for data protection Configured Default Encryption (SSE-S3) Set up Lifecycle Policies (auto-transition to Glacier after 30 days) Explored Simplified Compute Solutions:\nDeployed WordPress using Amazon Lightsail Blueprint (LAMP stack) Compared Lightsail vs EC2 trade-offs (simplicity vs control) Built Docker images for Node.js applications locally Deployed containerized applications to Lightsail Container Service Acquired hands-on experience with:\nMultiple compute options: EC2, Lightsail, Cloud9 Storage solutions: EBS (block), S3 (object) Both Linux and Windows workloads on AWS Basic containerization concepts preparing for ECS/EKS \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://chuong2610.github.io/AWS-Report/3-eventparticipated/3.3-event3/","title":"Event 3","tags":[],"description":"","content":"Comprehensive Report: AWS Cloud Mastery Series #2 Focus: FROM DEVOPS, IaC TO CONTAINER \u0026amp; OBSERVABILITY\n1. Core Objectives The event focused on revolutionizing software development and operations workflows on the Cloud platform:\nMindset Shift: Balancing feature release speed (Speed) and system stability (Stability) through DevOps culture and the Value Cycle. Infrastructure Modernization: Eliminating manual management risks (ClickOps) through Infrastructure as Code (IaC) methodology. Containerization Strategy: Providing a reference framework for selecting appropriate orchestration platforms: from simple (App Runner), specialized (ECS) to open standards (EKS). Deep Observability: Transitioning from passive monitoring to proactive system behavior analysis with CloudWatch and X-Ray. 2. Featured Speakers AWS Expert Team: Provided foundational knowledge and practical demo best practices. Tr·∫ßn Vƒ© \u0026amp; Long Quy Nghi√™m (FCJers 2024): Shared real-world experiences from the perspective of participants actively engaged in the First Cloud Journey program. 3. In-Depth Content 3.1. DevOps Mindset \u0026amp; CI/CD Pipeline: Foundation of Speed DevOps is not just a tool but a philosophy optimizing value flow:\nThe Value Cycle: Closed-loop process from Insight (Ideas) to Delivery (Handover). Redefining CI/CD: Continuous Integration (CI): Daily code commits, fail fast to detect errors early. Continuous Delivery: Automated deployment to Staging, but Production requires manual approval. Continuous Deployment: 100% automation to Production if all tests pass. Pipeline Principles: Build Once, Deploy Anywhere: Package source code once (Artifact) to ensure consistency across all environments. Measurement (DORA Metrics): Focus on 4 golden metrics: Deployment frequency, Lead time for changes, Change failure rate, and Mean time to recovery (MTTR). 3.2. Infrastructure as Code (IaC): From ClickOps to Code Mandatory shift from manual Console operations to Code-based management for Version Control and reusability:\nAWS CloudFormation: Native tool using YAML/JSON. Manages resources by Stack, clean deletion when removed. Terraform: Open-source (HCL), optimized for Multi-cloud. Plan -\u0026gt; Apply workflow allows previewing changes, safe for operations. AWS CDK: Uses modern programming languages (Python, Java\u0026hellip;) to build infrastructure. Supports Constructs (L1-L3) enabling complex system construction with just a few lines of code. Drift Detection: Critical feature detecting discrepancies between Code configuration and reality. 3.3. Containerization: Choosing the Right Platform There\u0026rsquo;s no best tool, only the most suitable tool for your needs:\nAmazon ECS: Simple, deeply integrated with AWS, for teams wanting to focus on Apps rather than Cluster management. Amazon EKS: International Kubernetes standard, for large systems requiring deep customization or Hybrid-cloud. AWS App Runner: \u0026ldquo;Zero-ops\u0026rdquo; solution, direct deployment from Code/Image to HTTPS URL without infrastructure concerns. Compute Options: EC2: Server management (High control, operational overhead). Fargate: Serverless for Containers (No OS management, just run Apps). 3.4. Observability: Beyond Monitoring Shifting from \u0026ldquo;Is the system alive?\u0026rdquo; to \u0026ldquo;Why is the system slow?\u0026rdquo;:\nAmazon CloudWatch: Central hub collecting Metrics, Logs, and Alarms (Alerts/Auto-scaling). AWS X-Ray (Distributed Tracing): Solves the \u0026ldquo;black box\u0026rdquo; problem in Microservices by mapping request paths, pinpointing latency bottlenecks or error origins precisely. 4. Personal Lessons and Reflections This specialized session reshaped my thinking about the role of Cloud engineers:\nFrom Ops to Platform Engineering: The modern role isn\u0026rsquo;t about manual deployment chasing but building platforms (Platform Builders). The goal is creating safe CI/CD \u0026ldquo;highways\u0026rdquo; for Developer self-service. Operational Discipline: Stability comes from discipline. The Immutability principle and banning manual fixes (ClickOps) on Production are vital for smooth system operations, avoiding human errors. Tool Selection Thinking: Understanding each tool\u0026rsquo;s pros and cons (CloudFormation vs Terraform, ECS vs EKS) helps me make accurate architectural decisions, optimizing costs and resources for projects. 5. Conclusion The \u0026ldquo;DevOps \u0026amp; IaC Mastery\u0026rdquo; event equipped me with a comprehensive maturation roadmap:\nThinking: Systematize and measure with data. Tools: Control infrastructure with Code (IaC). Operations: Optimize with Containers and Observability. These are indispensable pieces for building and operating large-scale, sustainable systems on AWS.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/3-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During my internship, I participated in four AWS events. Each one was a memorable experience that provided new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: Vietnam Cloud Day 2025 - Ho Chi Minh City Connect Edition for Builders (Track 1: GenAI \u0026amp; Data)\nDate \u0026amp; Time: 09:00, September 18, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: AWS Cloud Mastery Series #1\nDate \u0026amp; Time: 08:30, November 15, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AWS Cloud Mastery Series #2\nDate \u0026amp; Time: 08:30, November 17, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\nEvent 4 Event Name: AWS Cloud Mastery Series #3\nDate \u0026amp; Time: 08:30, November 29, 2025\nLocation: 26th Floor, Bitexco Tower, 02 Hai Trieu Street, Saigon Ward, Ho Chi Minh City\nRole: Attendee\n"},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.3-setup-bedrock/","title":"Setup AWS Bedrock","tags":[],"description":"","content":"Setting up AWS Bedrock \u0026amp; Knowledge Base In this section, you will configure AWS Bedrock to use Claude 3.5 Sonnet and create a Knowledge Base for document retrieval.\nStep 1: Enable Model Access IMPORTANT: You must enable model access before using Bedrock, otherwise you\u0026rsquo;ll get ValidationException errors.\nGo to AWS Console ‚Üí Services ‚Üí Bedrock In the left sidebar, click Model access (under Foundation models) Click Manage model access button (orange) Find and select these models: ‚úÖ Anthropic - Claude 3.5 Sonnet v2 (anthropic.claude-3-5-sonnet-20241022-v2:0) ‚úÖ Amazon - Titan Embeddings G1 - Text (for Knowledge Base) Click Request model access (bottom right) Wait for approval: Instant access models: Available immediately (green ‚úÖ) Other models: Wait 5-30 minutes (status changes from \u0026ldquo;In progress\u0026rdquo; ‚Üí \u0026ldquo;Access granted\u0026rdquo;) Verify models are enabled:\n# Using AWS CLI aws bedrock list-foundation-models --region us-west-2 # Or check in Console: # Bedrock ‚Üí Model access ‚Üí Status must be \u0026#34;Access granted\u0026#34; Step 2: Create S3 Bucket for Knowledge Base Knowledge Base requires an S3 bucket to store documents.\nGo to S3 ‚Üí Create bucket Bucket name: ev-rental-knowledge-docs (must be globally unique) Region: Same as your Bedrock region (e.g., us-west-2) Block all public access: ‚úÖ Enabled (recommended) Click Create bucket Step 3: Upload Documents to S3 Upload your rental policy documents (PDF, TXT, DOCX):\nSample documents to upload:\nrental-policy.pdf - Rental policies and terms pricing.pdf - Vehicle pricing information faq.txt - Frequently asked questions booking-process.pdf - How to book a vehicle Upload via Console:\nGo to your S3 bucket: ev-rental-knowledge-docs Click Upload ‚Üí Add files Select your documents Click Upload Upload via AWS CLI:\naws s3 cp rental-policy.pdf s3://ev-rental-knowledge-docs/ aws s3 cp pricing.pdf s3://ev-rental-knowledge-docs/ aws s3 cp faq.txt s3://ev-rental-knowledge-docs/ aws s3 cp booking-process.pdf s3://ev-rental-knowledge-docs/ Step 4: Create Knowledge Base Go to Bedrock ‚Üí Knowledge Bases ‚Üí Create Knowledge base name: ev-rental-knowledge-base Description: \u0026ldquo;VinFast EV rental policies and FAQs\u0026rdquo; Click Next Data source configuration:\nData source name: rental-docs S3 URI: s3://ev-rental-knowledge-docs/ Click Next Embeddings model:\nSelect: Titan Embeddings G1 - Text (amazon.titan-embed-text-v1) Vector database: Choose Bedrock managed (OpenSearch Serverless) (easiest option) Click Next Review and create:\nReview all settings Click Create knowledge base Wait for creation to complete (2-3 minutes) Step 5: Sync Data Source After Knowledge Base is created, you need to sync the data:\nIn your Knowledge Base, go to Data sources tab Select your data source: rental-docs Click Sync button Wait for sync to complete (check status: \u0026ldquo;Syncing\u0026rdquo; ‚Üí \u0026ldquo;Ready\u0026rdquo;) This process indexes all documents and creates vector embeddings Sync status:\nüîÑ Syncing: In progress ‚úÖ Ready: Completed successfully ‚ùå Failed: Check S3 permissions or document formats Step 6: Get Knowledge Base ID You\u0026rsquo;ll need this ID for your backend application:\nIn your Knowledge Base page Copy the Knowledge Base ID (format: 89CI1JSSE4 or similar) Save it in your notes - you\u0026rsquo;ll use it in the next step Example Knowledge Base ID:\nKnowledge Base ID: 89CI1JSSE4 Knowledge Base ARN: arn:aws:bedrock:us-west-2:123456789:knowledge-base/89CI1JSSE4 Step 7: Test Knowledge Base (Optional) Test your Knowledge Base directly in the console:\nGo to your Knowledge Base Click Test tab Enter a question: \u0026ldquo;What is the rental policy?\u0026rdquo; Click Run Verify it returns relevant information from your documents Verification Checklist Before moving to the next step, ensure:\n‚úÖ Claude 3.5 Sonnet v2 model access is granted ‚úÖ Titan Embeddings model access is granted ‚úÖ S3 bucket created with documents uploaded ‚úÖ Knowledge Base created and data synced successfully ‚úÖ Knowledge Base ID saved ‚úÖ Test query returns relevant results Troubleshooting Issue: \u0026ldquo;ValidationException: Model not enabled\u0026rdquo;\nSolution: Go to Bedrock ‚Üí Model access and enable the model Issue: \u0026ldquo;Sync failed\u0026rdquo;\nCheck S3 bucket permissions Verify document formats (PDF, TXT, DOCX supported) Check CloudWatch Logs for detailed errors Issue: \u0026ldquo;No results from Knowledge Base\u0026rdquo;\nEnsure documents are uploaded to S3 Run sync again Wait a few minutes after sync completes Try different query phrasing Next: Proceed to Deploy Backend API to build the FastAPI server.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Transition from self-managed databases to AWS Managed Database services Master Amazon RDS (Relational Database Service) with Multi-AZ deployment Learn NoSQL database concepts with Amazon DynamoDB Implement in-memory caching with Amazon ElastiCache Build Highly Available Web Applications architecture Understand AWS Managed Microsoft AD for enterprise integration Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Amazon RDS Essentials - Practice: + Deploy RDS with MySQL/PostgreSQL engine + Enable Multi-AZ deployment for high availability + Understand synchronous replication and automatic failover 09/22/2025 09/22/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn RDS Operations and Security - Practice: + Configure Security Groups for database access + Customize DB configurations via Parameter Groups + Set up Automated Backups and Manual Snapshots + Test Restore procedures (RPO validation) 09/23/2025 09/23/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Amazon DynamoDB NoSQL Essentials - Practice: + Design DynamoDB tables with Partition Keys + Compare Provisioned vs On-Demand capacity modes + Understand schemaless data model 09/24/2025 09/24/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Advanced DynamoDB Operations - Practice: + Perform PutItem, GetItem, Query, and Scan operations + Create Global Secondary Index (GSI) + Optimize queries to avoid expensive Scan operations 09/25/2025 09/25/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Amazon ElastiCache for In-Memory Caching - Practice: + Deploy ElastiCache with Redis engine + Implement Lazy Loading caching strategy + Place cache in Private Subnet for security 09/26/2025 09/26/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn Highly Available Web Applications Architecture - Practice: + Build 3-tier architecture (Web/App/DB) + Deploy Application Load Balancer (ALB) + Configure Multi-AZ deployment with RDS + Integrate S3 for static content 09/27/2025 09/27/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn AWS Managed Microsoft AD - Practice: + Set up AWS Managed Microsoft AD + Join Windows EC2 instances to domain + Implement Group Policy Objects (GPO) + Simulate enterprise environment migration 09/28/2025 09/28/2025 https://cloudjourney.awsstudygroup.com/ Week 3 Achievements: Mastered Managed Relational Databases with Amazon RDS:\nDeployed MySQL and PostgreSQL RDS instances Configured Multi-AZ deployment for automatic failover Understood synchronous replication mechanism Secured database with Security Group restrictions (no public internet access) Customized database parameters via Parameter Groups Implemented automated backup and point-in-time recovery Acquired NoSQL Database Skills with Amazon DynamoDB:\nDesigned tables with appropriate Partition Keys Understood schemaless/flexible data model advantages Compared Provisioned (predictable traffic) vs On-Demand (unpredictable traffic) capacity modes Performed CRUD operations: PutItem, GetItem, Query, Scan Created Global Secondary Indexes (GSI) for flexible querying Recognized performance impact of Scan vs Query operations Implemented In-Memory Caching:\nDeployed Amazon ElastiCache with Redis engine Applied Lazy Loading pattern (cache-aside strategy) Reduced database load through effective caching Placed cache in Private Subnet for low latency and security Built Production-Ready Highly Available Architecture:\nDesigned and implemented 3-tier architecture: Web Tier: EC2 instances in multiple AZs behind ALB Application Tier: EC2 instances with app logic Database Tier: RDS Multi-AZ for data persistence Configured Application Load Balancer for traffic distribution Integrated S3 for static content delivery Achieved fault tolerance and high availability Integrated Enterprise Directory Services:\nSet up AWS Managed Microsoft AD Joined Windows EC2 instances to Active Directory domain Implemented Group Policy Objects (GPO) for centralized management Simulated traditional on-premise environment migration to AWS Understood the transition benefits:\nFrom self-managed to managed services (reduced operational overhead) From single-AZ to Multi-AZ (improved availability) From SQL-only to SQL + NoSQL (flexibility in data modeling) From disk-based to in-memory storage (performance optimization) Storage Networking Database \u0026hellip; Successfully created and configured an AWS Free Tier account.\nBecame familiar with the AWS Management Console and learned how to find, access, and use services via the web interface.\nInstalled and configured AWS CLI on the computer, including:\nAccess Key Secret Key Default Region \u0026hellip; Used AWS CLI to perform basic operations such as:\nCheck account \u0026amp; configuration information Retrieve the list of regions View EC2 service Create and manage key pairs Check information about running services \u0026hellip; Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.4-deploy-backend/","title":"Deploy Backend API","tags":[],"description":"","content":"Deploy Backend API with FastAPI In this section, you will set up the FastAPI backend server that orchestrates the AI agent using Strands SDK.\nStep 1: Clone or Create Project Structure Create a new directory for the backend:\nmkdir ev-rental-backend cd ev-rental-backend Project structure:\nev-rental-backend/ ‚îú‚îÄ‚îÄ app/ ‚îÇ ‚îú‚îÄ‚îÄ __init__.py ‚îÇ ‚îú‚îÄ‚îÄ main.py # FastAPI app ‚îÇ ‚îú‚îÄ‚îÄ agent.py # Strands Agent setup ‚îÇ ‚îú‚îÄ‚îÄ tools.py # Agent tools (search vehicles, stations) ‚îÇ ‚îî‚îÄ‚îÄ database.py # PostgreSQL connection ‚îú‚îÄ‚îÄ requirements.txt # Python dependencies ‚îú‚îÄ‚îÄ .env # Environment variables ‚îî‚îÄ‚îÄ README.md Step 2: Install Dependencies Create requirements.txt:\nfastapi==0.104.1 uvicorn[standard]==0.24.0 strands-agent-sdk==0.1.5 boto3==1.34.10 psycopg2-binary==2.9.9 sqlalchemy==2.0.23 pydantic==2.5.2 python-dotenv==1.0.0 httpx==0.25.2 Install dependencies:\n# Create virtual environment python -m venv venv # Activate virtual environment # Windows: venv\\Scripts\\activate # macOS/Linux: source venv/bin/activate # Install packages pip install -r requirements.txt Step 3: Configure Environment Variables Create .env file with your AWS credentials and Knowledge Base ID:\n# AWS Credentials AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY AWS_REGION=us-west-2 # Bedrock Configuration BEDROCK_MODEL_ID=anthropic.claude-3-5-sonnet-20241022-v2:0 KNOWLEDGE_BASE_ID=89CI1JSSE4 # Database Configuration DATABASE_URL=postgresql://postgres:password@localhost:5432/ev_rental_db # API Configuration BACKEND_API_URL=http://localhost:8080 ‚ö†Ô∏è Security Note:\nNever commit .env to Git Add .env to .gitignore Step 4: Create Database Models Create app/database.py:\nfrom sqlalchemy import create_engine, Column, Integer, String, Text, DateTime from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker from datetime import datetime import os DATABASE_URL = os.getenv(\u0026#34;DATABASE_URL\u0026#34;) engine = create_engine(DATABASE_URL) SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine) Base = declarative_base() class ChatHistory(Base): __tablename__ = \u0026#34;chat_history\u0026#34; id = Column(Integer, primary_key=True, index=True) session_id = Column(String, index=True) user_message = Column(Text) agent_response = Column(Text) timestamp = Column(DateTime, default=datetime.utcnow) # Create tables Base.metadata.create_all(bind=engine) Step 5: Create Agent Tools Create app/tools.py:\nimport httpx import os from typing import List, Dict BACKEND_API_URL = os.getenv(\u0026#34;BACKEND_API_URL\u0026#34;, \u0026#34;http://localhost:8080\u0026#34;) async def search_vehicles(location: str = None, model: str = None) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Search for available vehicles\u0026#34;\u0026#34;\u0026#34; async with httpx.AsyncClient() as client: params = {} if location: params[\u0026#34;location\u0026#34;] = location if model: params[\u0026#34;model\u0026#34;] = model response = await client.get(f\u0026#34;{BACKEND_API_URL}/api/vehicles\u0026#34;, params=params) return response.json() async def search_stations(city: str = None) -\u0026gt; List[Dict]: \u0026#34;\u0026#34;\u0026#34;Search for charging stations\u0026#34;\u0026#34;\u0026#34; async with httpx.AsyncClient() as client: params = {} if city: params[\u0026#34;city\u0026#34;] = city response = await client.get(f\u0026#34;{BACKEND_API_URL}/api/stations\u0026#34;, params=params) return response.json() Step 6: Setup Strands Agent Create app/agent.py:\nimport boto3 import os from strands_agent import Agent, Tool # Initialize Bedrock client bedrock_client = boto3.client( \u0026#39;bedrock-runtime\u0026#39;, region_name=os.getenv(\u0026#39;AWS_REGION\u0026#39;), aws_access_key_id=os.getenv(\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;), aws_secret_access_key=os.getenv(\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;) ) # Initialize Knowledge Base client bedrock_agent_client = boto3.client( \u0026#39;bedrock-agent-runtime\u0026#39;, region_name=os.getenv(\u0026#39;AWS_REGION\u0026#39;), aws_access_key_id=os.getenv(\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;), aws_secret_access_key=os.getenv(\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;) ) # Create Agent agent = Agent( model_id=os.getenv(\u0026#39;BEDROCK_MODEL_ID\u0026#39;), client=bedrock_client, knowledge_base_id=os.getenv(\u0026#39;KNOWLEDGE_BASE_ID\u0026#39;), tools=[ Tool( name=\u0026#34;search_vehicles\u0026#34;, description=\u0026#34;Search for available electric vehicles for rent\u0026#34;, function=search_vehicles ), Tool( name=\u0026#34;search_stations\u0026#34;, description=\u0026#34;Find nearby charging stations\u0026#34;, function=search_stations ) ] ) Step 7: Create FastAPI Application Create app/main.py:\nfrom fastapi import FastAPI, HTTPException from fastapi.middleware.cors import CORSMiddleware from pydantic import BaseModel from app.agent import agent from app.database import SessionLocal, ChatHistory import uuid app = FastAPI(title=\u0026#34;EV Rental AI Agent API\u0026#34;) # Enable CORS app.add_middleware( CORSMiddleware, allow_origins=[\u0026#34;*\u0026#34;], allow_credentials=True, allow_methods=[\u0026#34;*\u0026#34;], allow_headers=[\u0026#34;*\u0026#34;], ) class ChatRequest(BaseModel): message: str session_id: str = None class ChatResponse(BaseModel): response: str session_id: str data: dict = None @app.post(\u0026#34;/chat\u0026#34;, response_model=ChatResponse) async def chat(request: ChatRequest): try: # Generate session ID if not provided session_id = request.session_id or str(uuid.uuid4()) # Get agent response agent_response = await agent.run(request.message) # Save to database db = SessionLocal() chat_record = ChatHistory( session_id=session_id, user_message=request.message, agent_response=agent_response[\u0026#34;response\u0026#34;] ) db.add(chat_record) db.commit() db.close() return ChatResponse( response=agent_response[\u0026#34;response\u0026#34;], session_id=session_id, data=agent_response.get(\u0026#34;data\u0026#34;) ) except Exception as e: raise HTTPException(status_code=500, detail=str(e)) @app.get(\u0026#34;/health\u0026#34;) async def health_check(): return {\u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;} Step 8: Run the Backend Server Start the FastAPI server:\n# Make sure virtual environment is activated uvicorn app.main:app --reload --port 8000 # You should see: # INFO: Uvicorn running on http://127.0.0.1:8000 # INFO: Application startup complete. Step 9: Test the API Test health endpoint:\ncurl http://localhost:8000/health # Response: {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;} Test chat endpoint:\ncurl -X POST http://localhost:8000/chat \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;message\u0026#34;: \u0026#34;Ch√≠nh s√°ch thu√™ xe c·ªßa b·∫°n l√† g√¨?\u0026#34;}\u0026#39; Expected response:\n{ \u0026#34;response\u0026#34;: \u0026#34;## üìã Ch√≠nh s√°ch thu√™ xe VinFast\\n\\n### üìÑ Gi·∫•y t·ªù c·∫ßn thi·∫øt:\\n- CMND/CCCD...\u0026#34;, \u0026#34;session_id\u0026#34;: \u0026#34;abc123-...\u0026#34;, \u0026#34;data\u0026#34;: null } Verification Checklist Before proceeding, ensure:\n‚úÖ Virtual environment created and activated ‚úÖ All dependencies installed ‚úÖ .env file configured with AWS credentials ‚úÖ PostgreSQL database running and connected ‚úÖ FastAPI server running on port 8000 ‚úÖ Health check endpoint returns {\u0026quot;status\u0026quot;:\u0026quot;healthy\u0026quot;} ‚úÖ Chat endpoint returns proper responses Troubleshooting Issue: \u0026ldquo;ModuleNotFoundError\u0026rdquo;\nSolution: Ensure virtual environment is activated and dependencies installed Issue: \u0026ldquo;Database connection failed\u0026rdquo;\nCheck PostgreSQL is running Verify DATABASE_URL in .env Test connection: psql -h localhost -U postgres -d ev_rental_db Issue: \u0026ldquo;Bedrock ValidationException\u0026rdquo;\nVerify AWS credentials in .env Ensure model access is granted in Bedrock console Check KNOWLEDGE_BASE_ID is correct Next: Proceed to Deploy Frontend to create the React chat interface.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/3-eventparticipated/3.4-event4/","title":"Event 4","tags":[],"description":"","content":"Comprehensive Report: AWS Cloud Mastery Series #3 Focus: CLOUD SECURITY \u0026amp; OPERATIONS MASTERY\n1. Core Objectives The event focused on developing System Thinking, transforming participants from passive to active defense models with 4 pillars:\nDefense in Depth: Establishing multi-layered security (Identity - Network - Data), ensuring safety even when one defense layer is breached. Governance: Building a scalable, synchronized, and strictly compliant foundation for hundreds of accounts. Automated Response: Replacing manual handling with instant automated processes to minimize damage. Community: Connecting and spreading knowledge through the AWS Cloud Clubs network. 2. Featured Speakers AWS Cloud Clubs Captains: Student leaders from HCMUTE, SGU, PTIT, HUFLIT sharing development opportunities. Technical Experts \u0026amp; AWS Community Builders: Industry-leading specialists in: Identity \u0026amp; Governance Detection \u0026amp; Monitoring Network Security Data Protection Incident Response 3. In-Depth Content 3.1. AWS Cloud Clubs: Talent Launchpad Introduction to the development ecosystem for students and future Cloud professionals:\nVision: Environment for leadership practice and global connections. Benefits: Build Skills through real projects, Build Community, and Build Opportunities for career expansion. The Badging Journey: Gamified advancement path (Bronze -\u0026gt; Diamond), providing capability recognition and exclusive event participation rights. 3.2. Identity \u0026amp; Governance: First Line of Defense On Cloud, the boundary is no longer the Network, but Identity.\nCredential Spectrum: Shifting from Long-term Credentials (high-risk Access Keys) to Short-term Credentials (self-expiring STS tokens). Least Privilege: Minimum privilege principle, eliminating indiscriminate Admin permission habits. AWS Organizations \u0026amp; SCPs: Tiered accounts by function (Security, Shared, Workloads) to isolate risks. Service Control Policies (SCPs): System \u0026ldquo;constitution\u0026rdquo; creating hard guardrails that even child Root accounts cannot violate (e.g., prohibiting CloudTrail log deletion). 3.3. Visibility \u0026amp; Detection: Comprehensive Monitoring \u0026ldquo;You cannot protect what you cannot see.\u0026rdquo;\nAmazon GuardDuty: Scout using AI/ML to analyze logs (CloudTrail, VPC Flow, DNS). Runtime Monitoring feature detects malware or privilege escalation deep within the OS. AWS Security Hub: Command center managing security posture (CSPM). Automatically audits compliance (CIS, PCI-DSS) and standardizes all alerts to a common format (ASFF). 3.4. Network Security: Zero Trust Thinking Building a \u0026ldquo;Digital Fortress\u0026rdquo; with the principle of trusting no one, including insiders.\nVPC Fundamentals: Security Groups (Stateful): Apply Micro-segmentation using Reference IDs instead of hard IPs. NACLs (Stateless): Hard block untrusted IP/Subnet ranges. Advanced Filtering: DNS Firewall: Block connections to hacker command and control (C2) servers. AWS Network Firewall: Next-generation firewall with Deep Packet Inspection and integrated Suricata IPS rules. Architecture: Use Transit Gateway for centralized connectivity and automated firewall updates upon detecting malicious IPs. 3.5. Data Protection: Core Asset Protection Envelope Encryption: KMS\u0026rsquo;s optimal mechanism - Master Key encrypts Data Key, Data Key encrypts data to ensure performance. Secrets Management: Use AWS Secrets Manager to eliminate hardcoded passwords in code. Most critical feature is Automatic Rotation (periodic automatic password changes). AWS Nitro System: Specialized hardware encryption ensuring data security without performance degradation (Zero Performance Impact). 3.6. Incident Response: Speed is Survival When defense fails, response speed determines damage.\nPrevention: Security from Code (IaC) to eliminate human-caused configuration errors (ClickOps). 5-Step Process: Prepare -\u0026gt; Detect -\u0026gt; Isolate (Most Critical) -\u0026gt; Eradicate \u0026amp; Recover -\u0026gt; Post-Incident (RCA). Automation: Use EventBridge combined with Lambda to automate responses (e.g., auto-close publicly exposed S3 buckets immediately), because humans cannot outpace automated Hacker Tools. 4. Personal Lessons and Reflections This specialized series helped me distill critical principles for Cloud security:\nIdentity is the new boundary: Strict IAM management and using SCPs in AWS Organizations is more important than building network firewalls. This is the foundation of enterprise governance. Automation is mandatory, not optional: Facing automated attacks, manual handling is meaningless. The combination of GuardDuty, EventBridge, and Lambda creates an automatic immune system. Security starts from Code: Applying IaC helps control changes and prevent configuration errors from the start, realizing the philosophy \u0026ldquo;Prevention is better than cure.\u0026rdquo; 5. Conclusion AWS Cloud Mastery Series #3 provides a comprehensive handbook for building solid Cloud systems:\nFoundation: Identity \u0026amp; Governance. Alarm System: Network \u0026amp; Detection. Vault \u0026amp; Protection: Data \u0026amp; Response. These are the final pieces to complete the capability picture from Operations, Development to Security on the AWS platform.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Week 4 Objectives: Automate system scalability with EC2 Auto Scaling Implement comprehensive monitoring with Amazon CloudWatch Master DNS management with Amazon Route 53 Optimize global content delivery with Amazon CloudFront and Lambda@Edge Learn command line automation with AWS CLI Understand advanced networking with VPC Peering Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn EC2 Auto Scaling - Practice: + Create Launch Templates with AMI, Instance Type, Security Group + Configure Auto Scaling Groups (Min=2, Max=4, Desired=2) + Set up Target Tracking Scaling Policy (CPU 50%) + Perform stress test to observe scale-out 09/29/2025 09/29/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Amazon CloudWatch Monitoring - Practice: + Monitor standard metrics (CPU, Disk I/O, Network) + Install CloudWatch Agent for custom metrics (Memory) + Create Alarms with SNS notifications + Configure alarm for CPU \u0026gt; 80% for 5 minutes 09/30/2025 09/30/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn CloudWatch Logs and Dashboards - Practice: + Push application logs to CloudWatch Logs + Create unified Dashboard for Web/DB/Cache health + Explore Grafana integration for advanced visualization 10/01/2025 10/01/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Amazon Route 53 DNS Management - Practice: + Create Hosted Zones + Configure Failover Routing with Health Checks + Set up Latency-based Routing + Implement automatic DNS failover to S3 maintenance page 10/02/2025 10/02/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Amazon CloudFront CDN - Practice: + Deploy CloudFront distribution for S3 content + Configure Origin Access Control (OAC) + Customize caching policies and TTL + Optimize global content delivery with Edge Locations 10/03/2025 10/03/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn CloudFront and Lambda@Edge - Practice: + Write Lambda functions running at Edge Locations + Modify HTTP headers dynamically + Implement A/B testing without origin server requests + Minimize latency with edge computing 10/04/2025 10/04/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn AWS CLI and VPC Peering - Practice: + Write Bash scripts for automation using AWS CLI + Auto-stop Dev instances + Connect two VPCs via VPC Peering + Week review and integration 10/05/2025 10/05/2025 https://cloudjourney.awsstudygroup.com/ Week 4 Achievements: Mastered Automatic Scalability with EC2 Auto Scaling:\nCreated Launch Templates defining complete instance configuration Configured Auto Scaling Groups with Min/Max/Desired capacity Implemented Target Tracking Scaling Policy (maintain 50% CPU) Successfully performed stress testing to observe automatic scale-out Integrated ASG with Application Load Balancer for seamless traffic distribution Achieved self-healing infrastructure (automatic instance replacement) Implemented Comprehensive Monitoring System:\nMonitored standard EC2 metrics: CPU, Disk I/O, Network throughput Deployed CloudWatch Agent for custom metrics (Memory Usage) Created CloudWatch Alarms with SNS email notifications Pushed application logs (/var/log/httpd) to CloudWatch Logs Built unified Dashboard visualizing system health across all tiers Explored advanced visualization with CloudWatch-Grafana integration Achieved DNS Mastery with Amazon Route 53:\nCreated and managed Hosted Zones for domain management Configured multiple routing policies: Simple Routing: Basic DNS resolution Failover Routing: Automatic failover with Health Checks Latency-based Routing: Direct users to lowest-latency region Implemented intelligent failover to S3 static maintenance page Optimized Global Content Delivery:\nDeployed Amazon CloudFront CDN with S3 origin Configured Origin Access Control (OAC) for secure S3 access Customized caching behavior with TTL settings Leveraged Edge Locations for global low-latency access Implemented Lambda@Edge for: Dynamic HTTP header modification A/B testing at the edge Request routing without origin server involvement Reduced latency and improved user experience worldwide Advanced CLI Automation Skills:\nWrote Bash automation scripts using AWS CLI Automated operational tasks (e.g., auto-stop Dev instances by tags) Mastered \u0026ndash;query and \u0026ndash;filter for precise JSON data extraction Transitioned from manual Console operations to programmatic control Developed skills essential for large-scale infrastructure management Expanded Network Architecture Knowledge:\nImplemented VPC Peering for inter-VPC communication Updated Route Tables to enable private network connectivity Understood non-transitive peering limitations Avoided internet gateway for VPC-to-VPC traffic (cost and security benefits) Completed Month 1 Milestone:\nBuilt production-ready 3-tier architecture with: Auto-scaling Web tier Self-healing capabilities Comprehensive monitoring (CloudWatch) Global performance optimization (CloudFront/Route 53) Automated operations (AWS CLI/ASG) Achieved Well-Architected Framework pillars: Reliability, Performance, and Operational Excellence Acquired the ability to connect between the web interface and CLI to manage AWS resources in parallel.\n\u0026hellip;\n"},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/","title":"Workshop","tags":[],"description":"","content":"Building an EV Rental AI Agent with AWS Bedrock Overview EV Rental AI Agent is an intelligent chatbot built to assist customers in the VinFast electric vehicle rental system. This workshop demonstrates how to leverage AWS Bedrock, Claude 3.5 Sonnet, and Knowledge Bases to create a conversational AI that can:\nAnswer natural language questions in Vietnamese Automatically search information from multiple sources Display data as interactive cards in the chat interface Retrieve available vehicles and charging stations Access rental policies and FAQs from a knowledge base In this workshop, you will learn how to:\nSetup AWS Bedrock - Enable AI models and create a Knowledge Base for document retrieval Deploy Backend API - Build a FastAPI server with Strands Agent SDK for intelligent tool selection Deploy Frontend - Create a React chat interface with Chakra UI components Test the System - Interact with the AI agent and verify all functionalities Content Workshop Overview Prerequisites Setup AWS Bedrock Deploy Backend API Deploy Frontend Testing the AI Agent Clean Up Resources "},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.5-deploy-frontend/","title":"Deploy Frontend","tags":[],"description":"","content":"Deploying the React Frontend In this section, you will set up and run the React chat interface that connects to your FastAPI backend.\nStep 1: Clone or Create React Project Create a new React application:\n# Using Create React App npx create-react-app ev-rental-frontend cd ev-rental-frontend # Or clone existing repository git clone https://github.com/your-org/ev-rental-frontend.git cd ev-rental-frontend Step 2: Install Dependencies Install required npm packages:\n# Core dependencies npm install axios react-markdown npm install @chakra-ui/react @emotion/react @emotion/styled framer-motion npm install react-icons # Or use package.json npm install Sample package.json dependencies:\n{ \u0026#34;dependencies\u0026#34;: { \u0026#34;react\u0026#34;: \u0026#34;^18.2.0\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^18.2.0\u0026#34;, \u0026#34;axios\u0026#34;: \u0026#34;^1.6.2\u0026#34;, \u0026#34;@chakra-ui/react\u0026#34;: \u0026#34;^2.8.2\u0026#34;, \u0026#34;@emotion/react\u0026#34;: \u0026#34;^11.11.1\u0026#34;, \u0026#34;@emotion/styled\u0026#34;: \u0026#34;^11.11.0\u0026#34;, \u0026#34;framer-motion\u0026#34;: \u0026#34;^10.16.16\u0026#34;, \u0026#34;react-markdown\u0026#34;: \u0026#34;^9.0.1\u0026#34;, \u0026#34;react-icons\u0026#34;: \u0026#34;^4.12.0\u0026#34; } } Step 3: Project Structure Your frontend should have this structure:\nev-rental-frontend/ ‚îú‚îÄ‚îÄ public/ ‚îÇ ‚îú‚îÄ‚îÄ index.html ‚îÇ ‚îî‚îÄ‚îÄ favicon.ico ‚îú‚îÄ‚îÄ src/ ‚îÇ ‚îú‚îÄ‚îÄ App.js # Main app component ‚îÇ ‚îú‚îÄ‚îÄ index.js # Entry point ‚îÇ ‚îú‚îÄ‚îÄ components/ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ChatInterface.js # Chat UI component ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ MessageList.js # Message display ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ InputBox.js # User input ‚îÇ ‚îú‚îÄ‚îÄ services/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ api.js # API calls to backend ‚îÇ ‚îú‚îÄ‚îÄ utils/ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ constants.js # Configuration ‚îÇ ‚îî‚îÄ‚îÄ styles/ ‚îÇ ‚îî‚îÄ‚îÄ App.css ‚îú‚îÄ‚îÄ package.json ‚îî‚îÄ‚îÄ .env Step 4: Configure Environment Variables Create .env file in the project root:\n# .env REACT_APP_API_URL=http://localhost:8000 REACT_APP_API_BASE_PATH=/api ‚ö†Ô∏è Important: In React, environment variables must start with REACT_APP_ prefix.\nStep 5: Create API Service Create src/services/api.js:\nimport axios from \u0026#39;axios\u0026#39;; const API_URL = process.env.REACT_APP_API_URL || \u0026#39;http://localhost:8000\u0026#39;; const api = axios.create({ baseURL: API_URL, headers: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, }, }); export const sendMessage = async (sessionId, message) =\u0026gt; { try { const response = await api.post(\u0026#39;/api/chat\u0026#39;, { session_id: sessionId, message: message, }); return response.data; } catch (error) { console.error(\u0026#39;API Error:\u0026#39;, error); throw error; } }; export default api; Step 6: Create Chat Interface Component Create src/components/ChatInterface.js:\nimport React, { useState, useEffect, useRef } from \u0026#39;react\u0026#39;; import { Box, VStack, HStack, Input, Button, Text, Container, Heading, } from \u0026#39;@chakra-ui/react\u0026#39;; import ReactMarkdown from \u0026#39;react-markdown\u0026#39;; import { sendMessage } from \u0026#39;../services/api\u0026#39;; function ChatInterface() { const [messages, setMessages] = useState([]); const [input, setInput] = useState(\u0026#39;\u0026#39;); const [loading, setLoading] = useState(false); const [sessionId] = useState(() =\u0026gt; `session-${Date.now()}-${Math.random().toString(36).substr(2, 9)}` ); const messagesEndRef = useRef(null); const scrollToBottom = () =\u0026gt; { messagesEndRef.current?.scrollIntoView({ behavior: \u0026#39;smooth\u0026#39; }); }; useEffect(() =\u0026gt; { scrollToBottom(); }, [messages]); const handleSend = async () =\u0026gt; { if (!input.trim()) return; const userMessage = { role: \u0026#39;user\u0026#39;, content: input }; setMessages((prev) =\u0026gt; [...prev, userMessage]); setInput(\u0026#39;\u0026#39;); setLoading(true); try { const response = await sendMessage(sessionId, input); const assistantMessage = { role: \u0026#39;assistant\u0026#39;, content: response.response, data: response.data, }; setMessages((prev) =\u0026gt; [...prev, assistantMessage]); } catch (error) { const errorMessage = { role: \u0026#39;error\u0026#39;, content: \u0026#39;Failed to get response. Please try again.\u0026#39;, }; setMessages((prev) =\u0026gt; [...prev, errorMessage]); } finally { setLoading(false); } }; return ( \u0026lt;Container maxW=\u0026#34;container.md\u0026#34; py={8}\u0026gt; \u0026lt;VStack spacing={4} align=\u0026#34;stretch\u0026#34;\u0026gt; \u0026lt;Heading size=\u0026#34;lg\u0026#34;\u0026gt;üöó EV Rental AI Agent\u0026lt;/Heading\u0026gt; \u0026lt;Box border=\u0026#34;1px\u0026#34; borderColor=\u0026#34;gray.200\u0026#34; borderRadius=\u0026#34;lg\u0026#34; p={4} h=\u0026#34;500px\u0026#34; overflowY=\u0026#34;auto\u0026#34; bg=\u0026#34;gray.50\u0026#34; \u0026gt; \u0026lt;VStack spacing={3} align=\u0026#34;stretch\u0026#34;\u0026gt; {messages.map((msg, idx) =\u0026gt; ( \u0026lt;Box key={idx} alignSelf={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;flex-end\u0026#39; : \u0026#39;flex-start\u0026#39;} maxW=\u0026#34;80%\u0026#34; bg={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;blue.500\u0026#39; : \u0026#39;white\u0026#39;} color={msg.role === \u0026#39;user\u0026#39; ? \u0026#39;white\u0026#39; : \u0026#39;black\u0026#39;} p={3} borderRadius=\u0026#34;lg\u0026#34; boxShadow=\u0026#34;sm\u0026#34; \u0026gt; {msg.role === \u0026#39;assistant\u0026#39; ? ( \u0026lt;ReactMarkdown\u0026gt;{msg.content}\u0026lt;/ReactMarkdown\u0026gt; ) : ( \u0026lt;Text\u0026gt;{msg.content}\u0026lt;/Text\u0026gt; )} \u0026lt;/Box\u0026gt; ))} {loading \u0026amp;\u0026amp; ( \u0026lt;Box alignSelf=\u0026#34;flex-start\u0026#34; maxW=\u0026#34;80%\u0026#34;\u0026gt; \u0026lt;Text color=\u0026#34;gray.500\u0026#34;\u0026gt;Typing...\u0026lt;/Text\u0026gt; \u0026lt;/Box\u0026gt; )} \u0026lt;div ref={messagesEndRef} /\u0026gt; \u0026lt;/VStack\u0026gt; \u0026lt;/Box\u0026gt; \u0026lt;HStack\u0026gt; \u0026lt;Input value={input} onChange={(e) =\u0026gt; setInput(e.target.value)} onKeyPress={(e) =\u0026gt; e.key === \u0026#39;Enter\u0026#39; \u0026amp;\u0026amp; handleSend()} placeholder=\u0026#34;Ask about vehicle rentals, policies, or charging stations...\u0026#34; disabled={loading} /\u0026gt; \u0026lt;Button onClick={handleSend} colorScheme=\u0026#34;blue\u0026#34; isLoading={loading} disabled={loading} \u0026gt; Send \u0026lt;/Button\u0026gt; \u0026lt;/HStack\u0026gt; \u0026lt;/VStack\u0026gt; \u0026lt;/Container\u0026gt; ); } export default ChatInterface; Step 7: Update App.js Update src/App.js:\nimport React from \u0026#39;react\u0026#39;; import { ChakraProvider } from \u0026#39;@chakra-ui/react\u0026#39;; import ChatInterface from \u0026#39;./components/ChatInterface\u0026#39;; function App() { return ( \u0026lt;ChakraProvider\u0026gt; \u0026lt;ChatInterface /\u0026gt; \u0026lt;/ChakraProvider\u0026gt; ); } export default App; Step 8: Run the Frontend Start the React development server:\nnpm start Expected output:\nCompiled successfully! You can now view ev-rental-frontend in the browser. Local: http://localhost:3000 On Your Network: http://192.168.1.10:3000 The application will automatically open in your browser at http://localhost:3000.\nStep 9: Test the Chat Interface Try these sample queries:\nKnowledge Base Query:\n\u0026ldquo;Ch√≠nh s√°ch thu√™ xe l√† g√¨?\u0026rdquo; \u0026ldquo;T√¥i c·∫ßn gi·∫•y t·ªù g√¨ ƒë·ªÉ thu√™ xe?\u0026rdquo; Vehicle Search:\n\u0026ldquo;T√¨m xe VinFast VF8 ·ªü H√† N·ªôi t·ª´ ng√†y 20/12\u0026rdquo; \u0026ldquo;C√≥ xe n√†o available?\u0026rdquo; Charging Station:\n\u0026ldquo;Tr·∫°m s·∫°c g·∫ßn Ho√†n Ki·∫øm\u0026rdquo; \u0026ldquo;T√¨m tr·∫°m s·∫°c ·ªü Qu·∫≠n 1\u0026rdquo; Verification Checklist Before proceeding, ensure:\n‚úÖ Node.js and npm installed ‚úÖ All dependencies installed successfully ‚úÖ .env file configured with backend URL ‚úÖ Backend server running on port 8000 ‚úÖ Frontend running on port 3000 ‚úÖ Chat interface loads without errors ‚úÖ Can send messages and receive responses ‚úÖ Markdown formatting displays correctly Troubleshooting Issue: \u0026ldquo;Module not found\u0026rdquo;\nSolution: Delete node_modules and run npm install again Check package.json for correct versions Issue: \u0026ldquo;Network Error\u0026rdquo; when sending messages\nCheck backend is running: curl http://localhost:8000/health Verify REACT_APP_API_URL in .env Check browser console for CORS errors Issue: \u0026ldquo;CORS policy error\u0026rdquo;\nEnsure backend has CORS middleware configured Check allow_origins includes http://localhost:3000 Issue: Port 3000 already in use\nChange port: PORT=3001 npm start Or kill existing process Issue: Markdown not rendering\nVerify react-markdown is installed Check import statement in ChatInterface.js Next: Proceed to Testing to verify all features work correctly.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/5-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"Throughout my 12-week internship at AWS Cloud Clubs Vietnam (from September 8, 2025 to December 12, 2025), I experienced an engaging and in-depth learning journey in Amazon Web Services and cloud computing technologies. This was an excellent opportunity for me to transform theoretical knowledge from university lectures into practical skills in a real cloud computing environment.\nMain Activities I Accomplished:\nWorkshop Development: Designed and deployed a hands-on workshop on AWS S3 and VPC Endpoint, including writing detailed documentation (in both English and Vietnamese), creating lab environments, and testing practical steps.\nAWS Services Research: Deep-dived into core services such as S3, VPC, IAM, EC2, CloudFormation, and best practices for security and cloud architecture.\nEvent Participation: Attended 4 large-scale AWS events in Ho Chi Minh City, learning about the latest trends in Generative AI, DevOps, IaC, Containers, and Cloud Security from AWS experts.\nSkills Significantly Improved:\nProficiency in designing and deploying cloud solutions using AWS Console and CLI Skills in writing standard, clear, and easy-to-follow technical documentation Deep understanding of cloud security architecture and networking Ability to translate and adapt technical terminology into Vietnamese Effective work in community environments and teamwork Work Ethic:\nI always demonstrated initiative and enthusiasm in every task. Not only completing assigned work but also seeking additional learning opportunities through events, webinars, and official AWS documentation. I also enthusiastically shared knowledge and supported other members in the AWS Cloud Clubs community, creating a positive collaborative environment.\nTo objectively reflect on my internship period, I would like to evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Understanding of the field, applying knowledge in practice, proficiency with tools, work quality ‚úÖ ‚òê ‚òê 2 Ability to learn Ability to absorb new knowledge and learn quickly ‚òê ‚úÖ ‚òê 3 Proactiveness Taking initiative, seeking out tasks without waiting for instructions ‚úÖ ‚òê ‚òê 4 Sense of responsibility Completing tasks on time and ensuring quality ‚úÖ ‚òê ‚òê 5 Discipline Adhering to schedules, rules, and work processes ‚òê ‚òê ‚úÖ 6 Progressive mindset Willingness to receive feedback and improve oneself ‚òê ‚úÖ ‚òê 7 Communication Presenting ideas and reporting work clearly ‚òê ‚úÖ ‚òê 8 Teamwork Working effectively with colleagues and participating in teams ‚úÖ ‚òê ‚òê 9 Professional conduct Respecting colleagues, partners, and the work environment ‚úÖ ‚òê ‚òê 10 Problem-solving skills Identifying problems, proposing solutions, and showing creativity ‚òê ‚úÖ ‚òê 11 Contribution to project/team Work effectiveness, innovative ideas, recognition from the team ‚úÖ ‚òê ‚òê 12 Overall General evaluation of the entire internship period ‚úÖ ‚òê ‚òê Needs Improvement Strengthen discipline and strictly comply with the rules and regulations of the company or any organization Improve problem-solving thinking Enhance communication skills in both daily interactions and professional contexts, including handling situations effectively "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Week 5 Objectives: Eliminate manual operations with operational thinking and Infrastructure as Code Master AWS Systems Manager for fleet management Learn secure server access with Session Manager (no SSH required) Deep dive into CloudFormation and AWS CDK for infrastructure automation Implement resource organization with Tags and Resource Groups Apply Attribute-Based Access Control (ABAC) with IAM and Tags Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn AWS Systems Manager (SSM) - Practice: + Configure IAM Role with AmazonSSMManagedInstanceCore + Use Run Command to execute shell commands on multiple instances + Collect software inventory across fleet for audit 10/06/2025 10/06/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Session Manager for Secure Access - Practice: + Access instances without SSH/RDP ports + Log sessions to S3 and CloudWatch Logs + Implement secure server access 10/07/2025 10/07/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn CloudFormation Infrastructure as Code - Practice: + Write YAML templates for VPC and EC2 + Use Change Sets for safe updates + Implement Drift Detection 10/08/2025 10/08/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn AWS CDK for Advanced Infrastructure - Practice: + Use TypeScript/Python for infrastructure + Leverage high-level constructs + Build custom reusable constructs 10/09/2025 10/09/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Resource Organization with Tags - Practice: + Implement tagging strategy + Create Resource Groups + Track costs by tags 10/10/2025 10/10/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn ABAC with IAM and Tags - Practice: + Implement Attribute-Based Access Control + Use tags for access policies + Review week 5 achievements 10/11/2025 10/11/2025 https://cloudjourney.awsstudygroup.com/ CN - Week Review and Practice + Review operational automation concepts + Practice IaC skills + Prepare for next week 10/12/2025 10/12/2025 https://cloudjourney.awsstudygroup.com/ Week 5 Achievements: Mastered AWS Systems Manager for Fleet Management:\nConfigured IAM Role with AmazonSSMManagedInstanceCore policy Executed Run Command to manage multiple instances simultaneously Automated software inventory collection across entire fleet Eliminated need for individual SSH connections to each server Implemented centralized patch management and compliance tracking Achieved scalable operational efficiency for large instance fleets Secured Server Access with Session Manager:\nDeployed Remote Server Access without SSH/RDP ports Closed port 22 on Security Groups for enhanced security Accessed instances via HTTPS protocol with IAM authentication Logged all session activity to S3 and CloudWatch Logs for audit compliance Implemented gold standard for secure server access Eliminated bastion host requirements and reduced attack surface Infrastructure as Code Mastery with CloudFormation:\nWrote YAML templates to define VPC and EC2 infrastructure Managed complete infrastructure lifecycle (Create/Update/Delete) Implemented Change Sets for safe infrastructure updates Utilized Drift Detection to identify manual configuration changes Achieved repeatable, version-controlled infrastructure deployments Eliminated manual configuration errors and inconsistencies Advanced Infrastructure Automation with AWS CDK:\nUsed TypeScript/Python for imperative infrastructure definition Leveraged high-level L2/L3 Constructs for rapid development Created VPC with single line of code vs dozens in CloudFormation Built custom reusable Constructs for organizational standards Solved circular dependencies and managed environment context Accelerated infrastructure development with programming language features Implemented Resource Organization with Tags:\nEstablished consistent tagging strategy (CostCenter, Environment, Owner) Created Resource Groups based on tag queries Enabled cost allocation tracking by project/team Simplified management of related resource collections Automated resource discovery and operational tasks Improved governance and cost visibility across organization Applied Attribute-Based Access Control (ABAC):\nImplemented IAM policies using resource tags for access control Created policies allowing actions only on resources with matching tags Enabled developers to manage only their tagged resources Eliminated need to update IAM policies for each new resource Achieved dynamic, scalable access control system Reduced IAM policy complexity and administrative overhead Achieved Operational Excellence Milestone:\nTransitioned from manual operations to automated infrastructure Eliminated configuration drift with IaC practices Implemented secure, auditable server access patterns Built foundation for enterprise-scale operations Mastered both declarative (CloudFormation) and imperative (CDK) IaC approaches Ready for advanced security and migration challenges "},{"uri":"https://chuong2610.github.io/AWS-Report/6-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":" Here, you can freely share your personal opinions about your experience participating in the First Cloud Journey program. This will help the FCJ team improve any shortcomings based on the following aspects:\nEND OF INTERNSHIP EVALUATION 1. Working Environment\nThe environment at FCJ is very open and professional. What impressed me most is the friendliness of the members; everyone is always willing to support each other at any time, even after working hours. The office space is neat and comfortable, helping me maintain high concentration.\nSmall area for improvement: I think the company should organize more social activities or regular team sessions to increase cohesion and help people understand each other better outside of work.\n2. Support from Mentor / Team Admin\nI highly appreciate the Mentor\u0026rsquo;s guidance approach: extremely detailed but not \u0026ldquo;hand-holding.\u0026rdquo; The mentor always encourages me to think independently and try solutions before providing suggestions, which helps me develop problem-solving abilities.\nAdditionally, the Admin team provides thorough support regarding processes and documentation, creating the most favorable conditions for me to focus on professional work.\n3. Relevance of Work to Academic Major\nThe assigned tasks have a strong connection with the foundational knowledge I learned at school, while also expanding into many real-world technologies that the curriculum hasn\u0026rsquo;t updated yet. This combination helps me both reinforce theory and quickly catch up with the practical requirements of businesses.\n4. Learning \u0026amp; Skill Development Opportunities\nThe internship was a major stepping stone in terms of skills. Professionally, I learned how to use project management tools and standard work processes. In terms of soft skills, I significantly improved my teamwork and professional communication abilities. Especially, the career path insights from the Mentor are valuable lessons that help me have clearer direction for the future.\n5. Culture \u0026amp; Team Spirit\nThe culture of mutual respect and support is a highlight here. Everyone works very seriously and focuses, but the atmosphere remains pleasant and not rigid. During peak periods (deadline rush), the \u0026ldquo;One Team\u0026rdquo; spirit is most evident: everyone supports each other wholeheartedly regardless of position or rank. I always feel respected and part of the collective even though I\u0026rsquo;m just an intern.\n6. Policies / Benefits for Interns\nThe reasonable allowance support policy and flexible working hours are big advantages, helping students like me balance study and work. Additionally, being able to participate in internal training sessions is a very practical benefit.\nADDITIONAL QUESTIONS What are you most satisfied with during your internship?\nIt\u0026rsquo;s the work mindset and dedication of the Mentor. I not only learned \u0026ldquo;what to do\u0026rdquo; but also \u0026ldquo;why to do it that way.\u0026rdquo; The way the Mentor empowers me to handle issues myself has helped me grow much more compared to when I first started.\nWhat do you think the company needs to improve for future interns?\nAs mentioned in section 1, I think the company should enhance internal connection activities (Teambuilding/Happy Hour) on a small scale so new interns can easily integrate and break down initial shyness barriers.\nIf recommending to friends, would you advise them to intern here? Why?\nAbsolutely yes. This is an ideal environment to transform textbook knowledge into practical capabilities. My friends will work in an open culture, be allowed to make mistakes and correct them, with the companionship of extremely dedicated Mentors.\nPROPOSALS \u0026amp; EXPECTATIONS Do you have any suggestions to improve the internship experience?\nI suggest the company could establish short \u0026ldquo;Sharing/Retrospective\u0026rdquo; sessions weekly or bi-weekly, where interns can share difficulties or interesting lessons they\u0026rsquo;ve just experienced with the whole team. This both increases interaction and helps everyone learn from each other faster.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.6-testing/","title":"Testing the System","tags":[],"description":"","content":"Testing the EV Rental AI Agent In this section, you will test all three core features of the AI Agent to ensure everything works correctly.\nPrerequisites for Testing Before testing, ensure:\n‚úÖ Backend server running on http://localhost:8000 ‚úÖ Frontend application running on http://localhost:3000 ‚úÖ PostgreSQL database is running and populated with test data ‚úÖ AWS Bedrock Knowledge Base is synced and ready Test Scenario 1: Knowledge Base Search The AI Agent should be able to answer questions about rental policies, pricing, and FAQs using the Knowledge Base.\nTest Queries:\nRental Policy:\nUser: \u0026#34;Ch√≠nh s√°ch thu√™ xe l√† g√¨?\u0026#34; Expected: Agent returns rental policy details from Knowledge Base Required Documents:\nUser: \u0026#34;T√¥i c·∫ßn gi·∫•y t·ªù g√¨ ƒë·ªÉ thu√™ xe?\u0026#34; Expected: Agent lists required documents (ID, license, deposit info) Pricing Information:\nUser: \u0026#34;Gi√° thu√™ xe VinFast VF8 l√† bao nhi√™u?\u0026#34; Expected: Agent provides pricing details from Knowledge Base Booking Process:\nUser: \u0026#34;L√†m th·∫ø n√†o ƒë·ªÉ ƒë·∫∑t xe?\u0026#34; Expected: Agent explains step-by-step booking process Verification:\n‚úÖ Response includes citation from Knowledge Base ‚úÖ Answer is relevant and accurate ‚úÖ Markdown formatting displays correctly ‚úÖ Response time is under 5 seconds Test Scenario 2: Vehicle Search The AI Agent should search the PostgreSQL database for available vehicles based on location and date.\nTest Queries:\nSearch by Location:\nUser: \u0026#34;T√¨m xe ·ªü H√† N·ªôi\u0026#34; Expected: Agent lists available vehicles in Hanoi Search by Model:\nUser: \u0026#34;C√≥ xe VinFast VF8 n√†o available kh√¥ng?\u0026#34; Expected: Agent shows VF8 vehicles with availability status Search with Date Range:\nUser: \u0026#34;T√¨m xe VF9 ·ªü H·ªì Ch√≠ Minh t·ª´ ng√†y 20/12 ƒë·∫øn 25/12\u0026#34; Expected: Agent searches vehicles available in that date range Search with Price Range:\nUser: \u0026#34;Xe n√†o d∆∞·ªõi 1 tri·ªáu ƒë·ªìng/ng√†y?\u0026#34; Expected: Agent filters vehicles by price Verification:\n‚úÖ Agent correctly extracts search parameters (location, model, dates) ‚úÖ Results include vehicle details (model, price, location, availability) ‚úÖ Data is fetched from PostgreSQL database ‚úÖ Results are formatted in a readable table or list Expected Response Format:\n## üöó Available Vehicles | Model | Location | Price/Day | Status | |-------|----------|-----------|--------| | VinFast VF8 | H√† N·ªôi | 800,000ƒë | Available | | VinFast VF9 | H√† N·ªôi | 1,200,000ƒë | Available | Test Scenario 3: Charging Station Finder The AI Agent should find nearby charging stations with real-time availability.\nTest Queries:\nSearch by District:\nUser: \u0026#34;Tr·∫°m s·∫°c g·∫ßn Qu·∫≠n Ho√†n Ki·∫øm\u0026#34; Expected: Agent lists charging stations in Hoan Kiem district Search by Address:\nUser: \u0026#34;T√¨m tr·∫°m s·∫°c ·ªü Qu·∫≠n 1, TP.HCM\u0026#34; Expected: Agent finds stations in District 1, HCMC Check Station Availability:\nUser: \u0026#34;Tr·∫°m s·∫°c n√†o c√≤n tr·ªëng?\u0026#34; Expected: Agent shows stations with available charging ports Filter by Connector Type:\nUser: \u0026#34;Tr·∫°m s·∫°c c√≥ CCS2 connector\u0026#34; Expected: Agent filters stations with CCS2 connectors Verification:\n‚úÖ Agent correctly identifies location from query ‚úÖ Results include station name, address, and availability ‚úÖ Connector types are listed ‚úÖ Real-time availability status is shown Expected Response Format:\n## ‚ö° Charging Stations Near You ### VinFast Station - Ho√†n Ki·∫øm üìç Address: 123 Tr·∫ßn H∆∞ng ƒê·∫°o, Ho√†n Ki·∫øm, H√† N·ªôi üîå Connectors: CCS2 (2 available), CHAdeMO (1 available) ‚è∞ Hours: 24/7 ‚úÖ Status: Available Test Scenario 4: Multi-Turn Conversations Test the agent\u0026rsquo;s ability to maintain context across multiple turns.\nTest Conversation:\nUser: \u0026#34;T√¥i mu·ªën thu√™ xe VF8\u0026#34; Agent: [Provides VF8 information] User: \u0026#34;Gi√° bao nhi√™u?\u0026#34; Agent: [Should understand context refers to VF8 pricing] User: \u0026#34;Tr·∫°m s·∫°c g·∫ßn ƒë√≥ ·ªü ƒë√¢u?\u0026#34; Agent: [Should find charging stations near VF8 location] Verification:\n‚úÖ Agent maintains conversation context ‚úÖ Pronouns and references are resolved correctly ‚úÖ Session ID persists across messages Test Scenario 5: Error Handling Test how the agent handles invalid or unclear queries.\nTest Cases:\nAmbiguous Query:\nUser: \u0026#34;Xe\u0026#34; Expected: Agent asks for clarification Unavailable Vehicle:\nUser: \u0026#34;T√¨m xe Tesla\u0026#34; Expected: Agent explains Tesla is not available, suggests alternatives Invalid Date:\nUser: \u0026#34;Thu√™ xe t·ª´ ng√†y 32/13\u0026#34; Expected: Agent detects invalid date and asks for correction Out of Scope:\nUser: \u0026#34;What\u0026#39;s the weather today?\u0026#34; Expected: Agent politely explains it can only help with EV rentals Verification:\n‚úÖ Agent handles errors gracefully ‚úÖ Provides helpful error messages ‚úÖ Suggests alternatives when possible Performance Testing Check system performance under normal usage:\nMetrics to Monitor:\nResponse Time:\nKnowledge Base queries: \u0026lt; 3 seconds Vehicle search: \u0026lt; 2 seconds Charging station search: \u0026lt; 2 seconds API Health:\ncurl http://localhost:8000/health Expected: 200 OK with health status\nBackend Logs: Check for errors in FastAPI console output\nFrontend Console: Open browser DevTools ‚Üí Console\nNo JavaScript errors API calls succeed (Network tab) Integration Testing Checklist Run through this comprehensive checklist:\n‚úÖ Knowledge Base Integration:\nAgent can retrieve policy information Citations are included in responses Bedrock API calls succeed ‚úÖ Database Integration:\nVehicle search queries PostgreSQL Results are accurate and up-to-date Database connection is stable ‚úÖ Backend API:\n/api/chat endpoint works /health endpoint responds Session management functions correctly ‚úÖ Frontend UI:\nMessages display correctly User input is captured Loading states work Markdown renders properly Auto-scroll functions ‚úÖ Error Handling:\nNetwork errors are caught Invalid inputs handled gracefully User receives helpful feedback Testing with Postman (Optional) Test backend API directly:\n1. Health Check:\nGET http://localhost:8000/health 2. Chat Request:\nPOST http://localhost:8000/api/chat Content-Type: application/json { \u0026#34;session_id\u0026#34;: \u0026#34;test-session-123\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Ch√≠nh s√°ch thu√™ xe l√† g√¨?\u0026#34; } Expected Response:\n{ \u0026#34;response\u0026#34;: \u0026#34;## üìã Ch√≠nh s√°ch thu√™ xe VinFast\\n\\n...\u0026#34;, \u0026#34;data\u0026#34;: null, \u0026#34;session_id\u0026#34;: \u0026#34;test-session-123\u0026#34; } Troubleshooting Test Failures Issue: Knowledge Base returns empty results\nCheck Knowledge Base is synced in AWS Console Verify KNOWLEDGE_BASE_ID in .env Test KB directly in Bedrock console Issue: Vehicle search returns no results\nCheck PostgreSQL database has test data Verify DATABASE_URL connection string Run SQL query directly: SELECT * FROM vehicles; Issue: Charging stations not found\nVerify backend API /stations endpoint works Check station data in database Test API call: curl http://localhost:8080/stations Issue: Frontend not connecting to backend\nCheck REACT_APP_API_URL in frontend .env Verify backend CORS allows http://localhost:3000 Check browser console for network errors Test Report Template Document your test results:\n## Test Report - EV Rental AI Agent **Date:** 2024-12-20 **Tester:** Your Name ### Test Results Summary - Total Tests: 15 - Passed: 14 - Failed: 1 - Success Rate: 93% ### Detailed Results #### Knowledge Base Search - [x] Rental policy query - PASS - [x] Required documents - PASS - [x] Pricing information - PASS - [ ] Booking process - FAIL (slow response) #### Vehicle Search - [x] Search by location - PASS - [x] Search by model - PASS - [x] Date range search - PASS #### Charging Station Finder - [x] District search - PASS - [x] Availability check - PASS ### Issues Found 1. Booking process query takes 7 seconds (\u0026gt; 5s threshold) - Root cause: Knowledge Base sync incomplete - Fix: Re-sync data source ### Recommendations - Monitor response times during peak usage - Add caching for frequently asked questions - Implement rate limiting Success! üéâ Your EV Rental AI Agent is now fully tested and operational.\nNext: Proceed to Cleanup to remove resources and avoid charges.\n"},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives: Build multi-layer defense-in-depth security architecture Protect applications with AWS WAF (Web Application Firewall) Master encryption with AWS KMS (Key Management Service) Secure credentials with AWS Secrets Manager and automatic rotation Implement intelligent threat detection with AWS GuardDuty Integrate user authentication with Amazon Cognito Achieve security compliance with AWS Security Hub Ensure private connectivity with VPC Endpoints Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn AWS WAF (Web Application Firewall) - Practice: + Create Web ACL and attach to ALB/CloudFront + Configure rules to block SQL Injection and XSS + Implement rate-limiting (100 requests/5min) + Mitigate application-layer DDoS attacks 10/13/2025 10/13/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn AWS KMS (Key Management Service) - Practice: + Create Customer Master Keys + Encrypt EBS volumes and S3 objects + Implement encryption at rest 10/14/2025 10/14/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn AWS Secrets Manager - Practice: + Store database credentials securely + Enable automatic rotation + Integrate with applications 10/15/2025 10/15/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn AWS GuardDuty - Practice: + Enable intelligent threat detection + Monitor security findings + Configure automated responses 10/16/2025 10/16/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Amazon Cognito - Practice: + Implement user authentication + Configure User Pools + Integrate with applications 10/17/2025 10/17/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn AWS Security Hub and VPC Endpoints - Practice: + Enable Security Hub for compliance + Configure VPC Endpoints + Review security best practices 10/18/2025 10/18/2025 https://cloudjourney.awsstudygroup.com/ CN - Week Review and Security Audit + Review security implementations + Perform security audit + Prepare for next week 10/19/2025 10/19/2025 https://cloudjourney.awsstudygroup.com/ Week 6 Achievements: Built Application Protection with AWS WAF:\nDeployed Web Application Firewall on ALB and CloudFront Created Web ACL with rules blocking SQL Injection and XSS attacks Implemented rate-based rules (100 requests/5min) to prevent abuse Mitigated application-layer DDoS attacks effectively Protected web applications from OWASP Top 10 vulnerabilities Achieved defense-in-depth security posture for web tier Achieved Encryption Mastery with AWS KMS:\nCreated Customer Managed Keys (CMK) for symmetric encryption Configured Key Policies controlling administrative and usage permissions Enabled encryption-at-rest for EBS volumes and S3 buckets Separated key management from key usage responsibilities Implemented cryptographic best practices for data protection Achieved compliance with encryption requirements (HIPAA, PCI-DSS) Secured Credentials with AWS Secrets Manager:\nStored RDS passwords in centrally managed Secrets Manager Configured automatic credential rotation with Lambda functions Updated application code to retrieve secrets via API calls Eliminated hardcoded credentials from configuration files Implemented just-in-time credential access Reduced credential exposure and security risks Implemented Intelligent Threat Detection with GuardDuty:\nEnabled continuous security monitoring across AWS account Analyzed CloudTrail Events, VPC Flow Logs, and DNS Logs Leveraged machine learning to detect anomalous behavior Identified threats: cryptocurrency mining, malicious IP access, privilege escalation Configured EventBridge for automated alert notifications Achieved proactive threat detection without infrastructure overhead Integrated User Authentication with Amazon Cognito:\nCreated User Pools for application user management Implemented secure sign-up and sign-in workflows Configured Identity Pools for AWS credential federation Enabled end-users to directly upload files to S3 with temporary credentials Eliminated backend server requirements for user authentication Built scalable, serverless authentication system Achieved Security Compliance with AWS Security Hub:\nEnabled centralized security findings aggregation Integrated GuardDuty, Macie, and Inspector findings Evaluated security posture against CIS AWS Foundations Benchmark Generated compliance scores and remediation guidance Unified security monitoring across multiple security services Improved security governance and audit readiness Ensured Private Connectivity with VPC Endpoints:\nDeployed S3 Gateway Endpoint for private S3 access Updated Private Subnet Route Tables for endpoint routing Eliminated internet gateway traversal for AWS service access Reduced data transfer costs and enhanced security Kept sensitive data within AWS internal network Achieved zero-trust network architecture for cloud services Completed Defense-in-Depth Security Architecture:\nBuilt multi-layer security spanning network, application, data layers Implemented security controls: WAF, KMS, Secrets Manager, GuardDuty, Cognito Achieved comprehensive threat protection and compliance posture Mastered encryption, authentication, and threat detection Ready for production workload security requirements Established security-first mindset for cloud architecture "},{"uri":"https://chuong2610.github.io/AWS-Report/4-workshop/4.7-cleanup/","title":"Cleanup Resources","tags":[],"description":"","content":"Cleaning Up Resources After completing the workshop, follow these steps to clean up all resources and avoid unnecessary AWS charges.\nWhy Cleanup is Important Cost Savings: AWS charges for active resources like Bedrock Knowledge Bases, S3 storage, and running services Security: Remove unused IAM credentials to maintain security best practices Organization: Keep your AWS account clean and organized Step 1: Delete AWS Bedrock Knowledge Base 1.1 Delete Knowledge Base Open the AWS Bedrock Console Navigate to Knowledge Bases in the left sidebar Select your Knowledge Base: ev-rental-knowledge-base Click Delete Confirm deletion by typing the Knowledge Base name Click Delete to confirm ‚ö†Ô∏è Note: This will also delete the associated data source connections.\n1.2 Delete S3 Bucket and Documents Open the S3 Console Find your bucket: ev-rental-knowledge-docs Select the bucket Click Empty to delete all objects Confirm by typing \u0026ldquo;permanently delete\u0026rdquo; After emptying, click Delete on the bucket Confirm by typing the bucket name Or use AWS CLI:\n# Delete all objects in bucket aws s3 rm s3://ev-rental-knowledge-docs --recursive # Delete the bucket aws s3 rb s3://ev-rental-knowledge-docs Step 2: Delete IAM User and Access Keys 2.1 Delete Access Keys Open the IAM Console Navigate to Users Select your user (e.g., bedrock-agent-user) Click on the Security credentials tab Under Access keys, find your access key Click Delete next to the access key Confirm deletion 2.2 Delete IAM User (Optional) If you created a dedicated IAM user for this workshop:\nIn the IAM Console, select the user Click Delete user Confirm by checking the box Click Delete Or use AWS CLI:\n# List access keys aws iam list-access-keys --user-name bedrock-agent-user # Delete access key (replace with your key ID) aws iam delete-access-key --user-name bedrock-agent-user --access-key-id AKIA5GPEMGJZK6E7PMEB # Delete user aws iam delete-user --user-name bedrock-agent-user Step 3: Stop Local Services 3.1 Stop FastAPI Backend In the terminal where FastAPI is running:\nPress Ctrl + C to stop the server\nDeactivate virtual environment:\ndeactivate Optionally delete the project folder:\n# On macOS/Linux rm -rf ev-rental-backend # On Windows rmdir /s ev-rental-backend 3.2 Stop React Frontend In the terminal where React is running:\nPress Ctrl + C to stop the development server\nOptionally delete the project folder:\n# On macOS/Linux rm -rf ev-rental-frontend # On Windows rmdir /s ev-rental-frontend 3.3 Stop PostgreSQL Database If you installed PostgreSQL locally for this workshop:\nOn macOS:\n# Stop PostgreSQL service brew services stop postgresql@14 On Linux:\nsudo systemctl stop postgresql On Windows:\n# Open Services (services.msc) # Find \u0026#34;PostgreSQL\u0026#34; service # Right-click ‚Üí Stop 3.4 Delete Database (Optional) If you want to completely remove the database:\n# Connect to PostgreSQL psql -U postgres # Drop database DROP DATABASE ev_rental_db; # Exit \\q Step 4: Remove Environment Files Delete sensitive .env files that contain credentials:\nBackend:\ncd ev-rental-backend rm .env Frontend:\ncd ev-rental-frontend rm .env ‚ö†Ô∏è Security Note: Never commit .env files to Git. Always add them to .gitignore.\nStep 5: Verify Cleanup 5.1 Check AWS Resources Verify all resources are deleted:\nBedrock Console:\nNo Knowledge Bases listed No model invocations active S3 Console:\nBucket ev-rental-knowledge-docs is deleted IAM Console:\nAccess keys are deleted IAM user removed (if you chose to delete it) 5.2 Check AWS Costs Open the AWS Billing Console Check Bills for the current month Verify charges: Bedrock charges should stop after Knowledge Base deletion S3 storage charges should stop after bucket deletion No ongoing compute charges Or use AWS CLI:\naws ce get-cost-and-usage \\ --time-period Start=2024-12-01,End=2024-12-31 \\ --granularity MONTHLY \\ --metrics UnblendedCost \\ --group-by Type=SERVICE Cost Breakdown Here\u0026rsquo;s what you may have been charged during the workshop:\nService Estimated Cost Notes AWS Bedrock - Claude 3.5 Sonnet ~$0.50 - $2.00 Depends on number of queries AWS Bedrock - Knowledge Base ~$0.10 - $0.50 Vector storage and retrieval S3 Storage ~$0.02 Minimal for small documents Data Transfer ~$0.05 Usually within free tier Total ~$0.67 - $2.57 Approximate for workshop ‚ö†Ô∏è Note: Most costs come from Bedrock API calls. The longer you test, the higher the cost.\nCleanup Checklist Before you finish, verify all items are complete:\nAWS Resources ‚úÖ Bedrock Knowledge Base deleted ‚úÖ S3 bucket emptied and deleted ‚úÖ IAM Access Keys deleted ‚úÖ IAM User deleted (optional) Local Resources ‚úÖ FastAPI backend stopped ‚úÖ React frontend stopped ‚úÖ PostgreSQL database stopped ‚úÖ PostgreSQL database dropped (optional) Sensitive Files ‚úÖ Backend .env file deleted ‚úÖ Frontend .env file deleted ‚úÖ No AWS credentials in project files Verification ‚úÖ AWS Console shows no active resources ‚úÖ Billing dashboard shows stopped charges ‚úÖ Local services not running Troubleshooting Cleanup Issues Issue: Cannot delete S3 bucket - \u0026ldquo;Bucket not empty\u0026rdquo;\nSolution: Empty all objects first using the S3 Console or CLI Command: aws s3 rm s3://bucket-name --recursive Issue: Cannot delete Knowledge Base - \u0026ldquo;In use\u0026rdquo;\nSolution: Wait a few minutes for any pending operations to complete Check if any API calls are still referencing it Issue: IAM User deletion fails - \u0026ldquo;User has attached policies\u0026rdquo;\nSolution: Detach all policies first Go to IAM ‚Üí Users ‚Üí Select user ‚Üí Permissions ‚Üí Detach policies Issue: PostgreSQL won\u0026rsquo;t stop\nSolution: Force kill the process On macOS/Linux: sudo killall postgres On Windows: Use Task Manager to end PostgreSQL processes Optional: Keep Learning If you want to continue experimenting:\nKeep These Resources: ‚úÖ IAM User (with minimal permissions) ‚úÖ Bedrock model access (no charge when not in use) What You Can Do Next: Add more documents to Knowledge Base Implement additional agent tools Deploy to AWS Lambda for serverless operation Add authentication and user management Integrate with real vehicle booking systems Conclusion üéâ Congratulations! You have successfully:\n‚úÖ Built an AI Agent using AWS Bedrock and Claude 3.5 Sonnet ‚úÖ Integrated Knowledge Bases for intelligent document retrieval ‚úÖ Created a FastAPI backend with Strands Agent SDK ‚úÖ Developed a React frontend for user interaction ‚úÖ Tested all features end-to-end ‚úÖ Cleaned up resources to avoid charges Key Takeaways: AI Agents can autonomously select tools and make decisions AWS Bedrock simplifies access to foundation models like Claude Knowledge Bases enable semantic search over documents Strands SDK provides a framework for building agent workflows FastAPI + React create a modern full-stack AI application Next Steps: Explore other Bedrock models (Llama 3, Mistral, etc.) Learn about RAG (Retrieval Augmented Generation) Build more complex agent workflows Deploy to production using AWS services "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Master migration strategies from on-premise to AWS cloud Migrate virtual machines with AWS VM Import/Export Execute database migration with DMS and Schema Conversion Tool Implement disaster recovery with AWS Elastic Disaster Recovery Centralize backup management with AWS Backup Build reliable systems with messaging (SQS and SNS) Understand shared storage solutions (EBS Multi-Attach and EFS) Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn VM Migration with AWS VM Import/Export - Practice: + Simulate on-premise environment with VirtualBox + Export VMs to .ova/.vmdk format + Upload to S3 and import as AMI + Launch EC2 from migrated AMI 10/20/2025 10/20/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Database Migration - Schema Conversion Tool (SCT) - Practice: + Convert Oracle schema to Aurora PostgreSQL + Automatic conversion of tables, keys, indexes + Identify stored procedures requiring manual fixes 10/21/2025 10/21/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn AWS Database Migration Service (DMS) - Practice: + Create Replication Instance + Configure Source and Target endpoints + Execute Full Load + CDC (Change Data Capture) + Minimize downtime during cutover 10/22/2025 10/22/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn AWS Elastic Disaster Recovery (DRS) - Practice: + Install DRS Agent on source servers + Configure continuous block-level replication + Perform Recovery Drill without affecting production + Validate RTO and RPO metrics 10/23/2025 10/23/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn AWS Backup Centralized Management - Practice: + Create Backup Plans for EC2, EBS, RDS, DynamoDB + Configure cross-region backup copy + Implement disaster recovery strategy + Manage all backups from single interface 10/24/2025 10/24/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn Messaging Systems with SQS and SNS - Practice: + Implement decoupling with SQS queues + Handle traffic spikes with buffering + Build Fan-out pattern with SNS Topics + Trigger multiple SQS queues for parallel processing 10/25/2025 10/25/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn Shared Storage Solutions - Practice: + Test EBS Multi-Attach with io2 volumes + Share block storage across multiple Nitro instances + Deploy Amazon EFS for shared file system (NFS) + Compare block vs file storage use cases 10/26/2025 10/26/2025 https://cloudjourney.awsstudygroup.com/ Week 7 Achievements: Mastered VM Migration with AWS VM Import/Export:\nSimulated on-premise environment using VirtualBox Exported virtual machines to .ova and .vmdk formats Uploaded VM images to S3 using AWS CLI Imported VM images as Amazon Machine Images (AMI) Successfully launched EC2 instances from migrated AMIs Executed lift-and-shift migration strategy effectively Executed Database Schema Conversion:\nUsed AWS Schema Conversion Tool (SCT) for database assessment Converted Oracle database schema to Aurora PostgreSQL Automatically transformed tables, keys, indexes, and constraints Identified stored procedures requiring manual refactoring Generated detailed assessment reports for migration planning Understood heterogeneous database migration challenges Implemented Continuous Database Migration with DMS:\nCreated DMS Replication Instance as migration intermediary Configured Source (Oracle) and Target (Aurora) endpoints Executed Full Load for initial data migration Enabled Change Data Capture (CDC) for ongoing replication Minimized downtime during production cutover Achieved near-zero downtime database migration Deployed Disaster Recovery with Elastic Disaster Recovery:\nInstalled AWS DRS Agent on source servers Configured continuous block-level replication to AWS Replicated data to staging area with minimal performance impact Performed Recovery Drills without affecting production systems Validated RTO (Recovery Time Objective) and RPO (Recovery Point Objective) Established robust DR strategy for business continuity Centralized Backup Management with AWS Backup:\nCreated unified backup plans for EC2, EBS, RDS, and DynamoDB Configured automated backup scheduling and retention policies Implemented cross-region backup copy for disaster recovery Managed all backups from single centralized interface Reduced operational complexity of multi-service backups Ensured compliance with data protection requirements Built Reliable Systems with Messaging:\nImplemented decoupling pattern with Amazon SQS queues Buffered requests during traffic spikes to prevent backend overload Built Fan-out architecture with SNS Topics Triggered multiple SQS queues for parallel processing workflows Achieved asynchronous, loosely-coupled system architecture Enhanced system reliability and fault tolerance Explored Shared Storage Solutions:\nTested EBS Multi-Attach with io2 volumes on Nitro instances Shared block storage across multiple instances for cluster applications Deployed Amazon EFS for NFS-based shared file systems Compared block storage (EBS) vs file storage (EFS) use cases Enabled multiple instances to access common data simultaneously Supported stateful applications requiring shared storage Completed Migration and DR Milestone:\nMastered multiple migration strategies: VM, database, application Implemented comprehensive disaster recovery architecture Achieved business continuity readiness with backup and replication Built resilient systems using messaging patterns Ready for cost optimization and advanced networking challenges Established foundation for cloud-first operations "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Master cost optimization and FinOps practices for cloud financial management Analyze spending patterns with AWS Cost Explorer and Cost \u0026amp; Usage Reports Implement right-sizing recommendations to eliminate resource waste Understand commitment-based pricing with Savings Plans and Reserved Instances Manage service quotas proactively to prevent deployment failures Build centralized network architecture with AWS Transit Gateway Monitor network traffic with VPC Flow Logs for security and troubleshooting Delegate billing access with proper IAM controls Automate EBS lifecycle management for backup optimization Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Cost Visualization and Analytics - Practice: + Analyze costs by Service, Region, and Tags with Cost Explorer + Enable Cost and Usage Report (CUR) export to S3 + Create hourly granular cost reports + Identify top spending services and resources 10/27/2025 10/27/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Advanced Cost Analytics with Athena - Practice: + Query CUR data using AWS Glue and Athena + Analyze data transfer costs between specific instances + Create custom cost allocation queries + Generate detailed cost breakdowns by hour/day 10/28/2025 10/28/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Right-Sizing with EC2 Resource Optimization - Practice: + Use AWS Compute Optimizer for instance recommendations + Analyze 14-day historical utilization data + Identify over-provisioned instances + Install CloudWatch Agent for memory metrics + Implement downsizing recommendations (m5.large ‚Üí m5.medium) 10/29/2025 10/29/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Cost Savings with Savings Plans and Reserved Instances - Practice: + Compare EC2 Instance Savings Plans vs Compute Savings Plans + Analyze commitment flexibility vs discount rates + Plan 1-year commitment for base workload + Calculate potential savings (up to 72%) + Purchase Savings Plan for production workloads 10/30/2025 10/30/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Managing Quotas with Service Quotas - Practice: + Review current service limits (vCPU, VPC, EIP) + Set up CloudWatch alarms for quota utilization (80% threshold) + Request quota increases proactively + Prevent deployment failures due to limits 10/31/2025 10/31/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn Centralized Network Management with Transit Gateway - Practice: + Replace mesh VPC Peering with hub-and-spoke model + Connect 3 VPCs and 1 VPN to Transit Gateway + Configure Transit Gateway route tables + Implement network segmentation (Dev/Prod isolation) + Allow Shared Services VPC access from all environments 11/01/2025 11/01/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn Network Monitoring and Billing Delegation - Practice: + Enable VPC Flow Logs for traffic analysis + Create IAM roles for finance team + Grant billing access + Review week 8 achievements 11/02/2025 11/02/2025 https://cloudjourney.awsstudygroup.com/ Week 8 Achievements: Mastered Cost Visualization and Analytics:\nAnalyzed spending patterns by Service, Region, and custom Tags Enabled Cost and Usage Report (CUR) for detailed cost data export Generated hourly granular cost reports exported to S3 Identified top spending services and cost optimization opportunities Created cost allocation tracking for projects and teams Established FinOps foundation for continuous cost management Implemented Advanced Cost Analysis with Athena:\nUsed AWS Glue to catalog CUR data in S3 Queried complex cost patterns with Amazon Athena SQL Analyzed data transfer costs between specific instances Created custom cost allocation reports by hour and day Answered detailed cost questions: \u0026ldquo;How much did data transfer between two instances cost?\u0026rdquo; Achieved granular cost visibility for optimization decisions Optimized Resources with Right-Sizing:\nLeveraged AWS Compute Optimizer for instance recommendations Analyzed 14-day historical CPU, memory, and network utilization Identified over-provisioned instances wasting resources Installed CloudWatch Agent for accurate memory metrics Implemented downsizing: m5.large ‚Üí m5.medium for underutilized workloads Achieved 30-50% cost savings on compute resources Maximized Savings with Commitment-Based Pricing:\nCompared EC2 Instance Savings Plans (highest discount, least flexibility) Evaluated Compute Savings Plans (flexibility across EC2/Fargate/Lambda) Planned 1-year commitment for predictable base workload Calculated potential savings: up to 72% vs On-Demand pricing Purchased Savings Plans for production workloads Balanced cost savings with workload flexibility requirements Proactively Managed Service Quotas:\nReviewed current service limits: vCPU, VPC, Elastic IPs, etc. Set up CloudWatch Alarms for quota utilization at 80% threshold Submitted quota increase requests before reaching limits Prevented deployment failures and business disruptions Established proactive capacity planning process Avoided emergency quota increase requests Built Centralized Network with Transit Gateway:\nReplaced complex mesh VPC Peering with hub-and-spoke architecture Connected 3 VPCs (Dev/Staging/Prod) and 1 VPN to Transit Gateway Configured Transit Gateway route tables for traffic control Implemented network segmentation: Dev cannot access Prod Enabled all environments to access Shared Services VPC Simplified network management and reduced peering complexity Enhanced Network Visibility with VPC Flow Logs:\nEnabled Flow Logs for comprehensive traffic analysis Debugged connection issues by analyzing ACCEPT/REJECT status Identified Security Groups and NACLs blocking traffic Detected network anomalies and suspicious traffic patterns Improved security posture with network monitoring Reduced mean time to resolution (MTTR) for network issues Implemented Billing Access Delegation:\nCreated IAM roles with billing-only permissions for finance team Granted cost dashboard access without technical resource permissions Enforced separation of duties principle Enabled finance team to analyze costs independently Maintained security while improving financial visibility Achieved compliance with organizational governance requirements Automated EBS Lifecycle Management:\nConfigured Data Lifecycle Manager for automated snapshot creation Set retention policies: keep last 7 days, automatically delete older backups Scheduled snapshot creation during low-usage windows Reduced storage costs by eliminating manual snapshot management Ensured consistent backup coverage without human error Improved backup reliability and cost efficiency Deployed Backup Anomaly Detection:\nEnabled anomaly detection for EBS backup monitoring Identified unusual backup patterns indicating potential issues Detected early signs of ransomware or system failures Configured automated alerts for backup anomalies Enhanced data protection with intelligent monitoring Achieved proactive incident response for backup systems Completed Cost Optimization and Advanced Networking Milestone:\nMastered FinOps practices for cloud financial management Achieved 30-70% cost savings through right-sizing and commitments Built scalable, centralized network architecture Implemented comprehensive cost visibility and governance Established automated backup lifecycle and anomaly detection Ready for containerization and modernization challenges in Month 3 Transitioned from \u0026ldquo;building and securing\u0026rdquo; to \u0026ldquo;optimizing and modernizing\u0026rdquo; "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Master containerization fundamentals with Docker Deploy serverless containers with Amazon ECS and AWS Fargate Automate ECS infrastructure with AWS CDK Learn Kubernetes on AWS with Amazon EKS Deploy applications to EKS clusters Build CI/CD pipelines for containerized applications Explore Red Hat OpenShift Service on AWS (ROSA) Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Containerization with Docker - Practice: + Write optimized Dockerfile with multi-stage builds + Build and test Docker images locally + Create Amazon ECR repository + Push images to ECR for secure private storage + Reduce image size with optimization techniques 11/03/2025 11/03/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Amazon ECS and AWS Fargate - Practice: + Create ECS Task Definitions (CPU/RAM allocation) + Choose Fargate launch type (serverless) + Deploy ECS Service with desired replica count + Integrate with Application Load Balancer + Achieve zero infrastructure management 11/04/2025 11/04/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Infrastructure as Code for ECS with CDK - Practice: + Use ApplicationLoadBalancedFargateService construct + Deploy complete architecture (VPC, ALB, ECS) with 20 lines of code + Automate ECS infrastructure deployment + Leverage high-level CDK constructs for rapid development 11/05/2025 11/05/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Getting Started with Amazon EKS - Practice: + Initialize EKS Control Plane with eksctl or CDK + Configure Managed Node Groups for worker nodes + Automate node patching and upgrades + Set up kubectl for cluster management + Understand Kubernetes on AWS architecture 11/06/2025 11/06/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Deploying Applications to Amazon EKS - Practice: + Write Kubernetes manifests (Deployment, Service, Ingress) + Deploy applications using kubectl apply + Install AWS Load Balancer Controller + Auto-create ALB from Ingress resources + Manage application lifecycle on Kubernetes 11/07/2025 11/07/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn CI/CD Pipelines for ECS and EKS - Practice: + Build pipeline: CodeCommit ‚Üí CodeBuild ‚Üí ECR ‚Üí ECS/EKS + Automate image building and testing + Implement Blue/Green deployment strategy + Minimize deployment risk with automated rollback + Achieve continuous delivery for containers 11/08/2025 11/08/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn Red Hat OpenShift Service on AWS (ROSA) - Practice: + Understand managed OpenShift on AWS + Explore migration path for existing OpenShift workloads + Compare ROSA vs EKS features + Identify use cases for enterprise OpenShift customers 11/09/2025 11/09/2025 https://cloudjourney.awsstudygroup.com/ Week 9 Achievements: Mastered Docker Containerization Fundamentals:\nWrote optimized Dockerfiles with multi-stage build patterns Built lightweight container images with minimal layers Tested applications locally in Docker containers Created private Amazon ECR repositories Pushed Docker images to ECR with secure authentication Achieved portable, consistent application deployment across environments Deployed Serverless Containers with ECS and Fargate:\nCreated ECS Task Definitions specifying CPU and memory requirements Selected Fargate launch type for zero infrastructure management Deployed ECS Services maintaining desired replica count Integrated ECS with Application Load Balancer for traffic distribution Achieved automatic container orchestration without managing EC2 instances Eliminated server management overhead while maintaining control Automated ECS Infrastructure with AWS CDK:\nLeveraged ApplicationLoadBalancedFargateService L3 construct Deployed complete containerized architecture (VPC, ALB, ECS Cluster, Service) with ~20 lines of code Automated infrastructure provisioning with programming language advantages Achieved rapid development and deployment of container infrastructure Reduced infrastructure code complexity by 80% vs CloudFormation Established reusable patterns for container deployments Launched Production-Grade Kubernetes with Amazon EKS:\nInitialized EKS Control Plane using eksctl and CDK EKS Blueprints Configured Managed Node Groups with automated patching and upgrades Set up kubectl for Kubernetes cluster management Understood EKS architecture: Control Plane (AWS-managed), Data Plane (Customer VPC) Eliminated Kubernetes control plane operational overhead Achieved enterprise-grade Kubernetes without infrastructure complexity Deployed Applications to EKS Successfully:\nWrote standard Kubernetes manifests (Deployment, Service, Ingress YAML) Deployed multi-replica applications with kubectl apply Installed AWS Load Balancer Controller for AWS integration Automatically created Application Load Balancers from Ingress resources Managed rolling updates and rollbacks with Kubernetes native tools Achieved cloud-native application deployment on Kubernetes Built Complete CI/CD Pipelines for Containers:\nDesigned end-to-end pipeline: CodeCommit ‚Üí CodeBuild ‚Üí ECR ‚Üí CodeDeploy Automated Docker image building, testing, and security scanning Implemented Blue/Green deployment strategy for zero-downtime updates Configured automatic rollback on deployment failures Integrated with ECS and EKS for seamless container updates Achieved continuous delivery with deployment automation Explored Enterprise OpenShift on AWS:\nUnderstood Red Hat OpenShift Service on AWS (ROSA) Evaluated ROSA as managed OpenShift alternative to EKS Identified migration path for on-premise OpenShift workloads Compared OpenShift developer experience vs vanilla Kubernetes Recognized use cases for enterprises with OpenShift expertise Expanded container orchestration options for hybrid cloud Completed Container Technology Milestone:\nTransitioned from virtual machines to containerized architectures Mastered both ECS (AWS-native) and EKS (Kubernetes-based) platforms Implemented serverless containers eliminating infrastructure management Built automated CI/CD pipelines for container deployments Achieved modern, scalable application deployment patterns Ready for serverless and event-driven architecture challenges Established foundation for cloud-native application development "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Master serverless computing fundamentals with AWS Lambda Build complete serverless backends with Lambda, API Gateway, and DynamoDB Implement authentication and authorization with Amazon Cognito Configure custom domains and SSL certificates for serverless APIs Design event-driven architectures with S3, SQS, and SNS Orchestrate complex workflows with AWS Step Functions Build real-time GraphQL APIs with AWS AppSync Monitor and trace serverless applications with AWS X-Ray Automate serverless deployments with AWS SAM Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Serverless Backend with Lambda, API Gateway, DynamoDB - Practice: + Write Lambda functions for business logic (CRUD operations) + Integrate Lambda with DynamoDB using AWS SDK + Create REST API with API Gateway + Configure Lambda proxy integration + Build complete serverless CRUD API 11/10/2025 11/10/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Serverless Authentication with Amazon Cognito - Practice: + Create Cognito User Pool for authentication + Configure sign-up and sign-in workflows + Add Cognito Authorizer to API Gateway + Block unauthorized API requests + Implement JWT token validation 11/11/2025 11/11/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Custom Domains and SSL for Serverless Applications - Practice: + Request ACM certificates for custom domains + Configure API Gateway custom domain names + Map custom domains (api.example.com) to API stages + Replace default AWS endpoints with branded URLs + Implement SSL/TLS encryption 11/12/2025 11/12/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Event-Driven Architecture with SQS and SNS - Practice: + Build asynchronous order processing with SQS + Trigger Lambda from SQS queue messages + Implement Fan-out pattern with SNS + Process orders and send notifications in parallel + Achieve decoupled, scalable architecture 11/13/2025 11/13/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn S3 Event-Driven Processing - Practice: + Configure S3 event notifications to trigger Lambda + Automatically process uploaded images + Generate thumbnails on S3 PUT events + Implement real-time file processing + Build serverless data pipelines 11/14/2025 11/14/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn Workflow Orchestration with AWS Step Functions - Practice: + Design state machines for order approval workflow + Chain multiple Lambda functions (Check inventory ‚Üí Charge card ‚Üí Send email) + Implement error handling with Retry/Catch + Add conditional logic and parallel processing + Eliminate \u0026ldquo;Lambda Pinball\u0026rdquo; anti-pattern 11/15/2025 11/15/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn Real-Time GraphQL with AWS AppSync - Practice: + Create GraphQL schema and API with AppSync + Configure DynamoDB as data source + Implement GraphQL queries, mutations, subscriptions + Enable real-time updates via WebSocket + Build chat applications and live dashboards 11/16/2025 11/16/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Mastered Serverless Computing Fundamentals:\nBuilt complete serverless backend with Lambda + API Gateway + DynamoDB Wrote Lambda functions handling business logic (CRUD operations) Integrated Lambda with DynamoDB using AWS SDK (Boto3/JavaScript) Created REST APIs with API Gateway and Lambda proxy integration Eliminated server management and infrastructure overhead Achieved automatic scaling with pay-per-request pricing Implemented Serverless Authentication and Authorization:\nCreated Amazon Cognito User Pools for user management Configured secure sign-up, sign-in, and password reset workflows Added Cognito Authorizer to API Gateway for JWT validation Blocked unauthorized requests automatically Implemented fine-grained access control with Cognito groups Achieved enterprise-grade authentication without custom code Configured Custom Domains and SSL Certificates:\nRequested and validated ACM SSL/TLS certificates Configured API Gateway custom domain names Mapped custom domains (api.example.com) to API stages Replaced unfriendly AWS endpoints with branded URLs Implemented HTTPS encryption for all API traffic Enhanced professional appearance and security posture Built Event-Driven Architectures:\nImplemented asynchronous order processing with Amazon SQS Triggered Lambda functions from SQS queue messages Built Fan-out pattern with SNS Topics for parallel processing Processed orders, sent emails, and updated inventory simultaneously Achieved loose coupling and high scalability Eliminated synchronous dependencies between components Implemented S3-Triggered Serverless Processing:\nConfigured S3 event notifications to invoke Lambda automatically Processed uploaded images in real-time (thumbnail generation) Built serverless data pipelines triggered by file uploads Implemented automatic image resizing, format conversion, metadata extraction Achieved zero-latency file processing Eliminated polling and manual processing workflows Orchestrated Complex Workflows with Step Functions:\nDesigned visual state machines for multi-step business processes Chained Lambda functions: Check inventory ‚Üí Charge payment ‚Üí Send confirmation Implemented error handling with automatic Retry and Catch blocks Added conditional branching (if/else) and parallel execution Eliminated complex Lambda coordination code (\u0026ldquo;Lambda Pinball\u0026rdquo;) Achieved reliable, observable workflow execution Built Real-Time GraphQL APIs with AppSync:\nCreated GraphQL schemas defining types, queries, mutations, subscriptions Configured AppSync with DynamoDB as primary data source Implemented flexible GraphQL queries replacing multiple REST endpoints Enabled real-time updates via GraphQL Subscriptions over WebSocket Built live chat applications and auto-updating dashboards Achieved modern API design with real-time capabilities Implemented Distributed Tracing with X-Ray:\nEnabled AWS X-Ray for serverless application tracing Visualized service maps showing request flow: API Gateway ‚Üí Lambda ‚Üí DynamoDB Analyzed latency breakdown for each service segment Identified performance bottlenecks and cold start issues Debugged distributed applications with end-to-end traces Improved application performance with data-driven optimization Automated Deployments with AWS SAM:\nUsed SAM templates for Infrastructure as Code Tested Lambda and API Gateway locally with sam local start-api Debugged serverless applications on local machine with Docker Deployed serverless applications with single sam deploy command Achieved consistent, repeatable serverless deployments Accelerated development with local testing capabilities Completed Serverless Architecture Milestone:\nTransitioned from container-based to serverless architectures Built production-ready serverless applications with zero server management Implemented authentication, event-driven patterns, and workflow orchestration Achieved automatic scaling with pay-per-use cost model Mastered complete serverless technology stack Ready for application modernization and microservices challenges Established foundation for cloud-native, event-driven development "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11 Objectives: Master application modernization strategies from monolith to microservices Apply Strangler Fig Pattern for incremental migration Build independent microservices with database-per-service pattern Implement asynchronous microservices communication with messaging Build complete CI/CD pipelines for continuous delivery Adopt DevOps culture and practices with AWS tools Deploy simplified applications with AWS Elastic Beanstalk Build enterprise-grade WordPress architecture on AWS Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Monolith to Microservices Migration Strategy - Practice: + Analyze monolithic application architecture + Identify bounded contexts for service decomposition + Apply Strangler Fig Pattern for incremental migration + Select Shopping Cart module for extraction + Plan migration without full system rewrite 11/17/2025 11/17/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Create and Deploy Microservice - Practice: + Rewrite Shopping Cart module as independent microservice + Implement microservice with Node.js on Lambda or Fargate + Separate microservice database (DynamoDB) from monolith DB + Apply database-per-service pattern + Achieve data independence and loose coupling 11/18/2025 11/18/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Microservices Messaging and Eventing - Practice: + Replace synchronous HTTP calls with asynchronous messaging + Implement event-driven communication via EventBridge + Use SNS/SQS for service-to-service messaging + Eliminate tight coupling between microservices + Improve resilience and scalability 11/19/2025 11/19/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn CI/CD for Application Release - Practice: + Build complete pipeline: Source ‚Üí Build ‚Üí Test ‚Üí Deploy + Use CodeCommit for source control + Automate builds with CodeBuild + Deploy with CodeDeploy + Add manual approval gate before production deployment 11/20/2025 11/20/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn DevOps Culture with AWS CodePipeline - Practice: + Integrate security testing in build phase (Shift Left) + Add SAST/DAST security scans to pipeline + Automatically fail pipeline on security vulnerabilities + Implement continuous security validation + Adopt DevSecOps practices 11/21/2025 11/21/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn AWS Elastic Beanstalk Workshop - Practice: + Deploy Node.js application to Elastic Beanstalk + Use platform-as-a-service for simplified deployment + Automatic provisioning of EC2, ALB, Auto Scaling + Compare Beanstalk (simplicity) vs ECS/EKS (control) + Evaluate trade-offs for different use cases 11/22/2025 11/22/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn Enterprise WordPress on AWS - Practice: + Design scalable WordPress architecture + Use Aurora Serverless for database + Share wp-content with Amazon EFS across instances + Implement ElastiCache for object caching + Deploy CloudFront CDN for static content + Build production-ready WordPress at scale 11/23/2025 11/23/2025 https://cloudjourney.awsstudygroup.com/ Week 11 Achievements: Mastered Monolith to Microservices Migration:\nAnalyzed monolithic application identifying tight coupling and dependencies Identified bounded contexts using Domain-Driven Design principles Applied Strangler Fig Pattern for gradual, risk-minimized migration Selected Shopping Cart module as first microservice extraction candidate Avoided big-bang rewrite risks with incremental approach Established migration strategy for legacy application modernization Built Independent Microservices:\nRewrote Shopping Cart module as standalone microservice Implemented microservice using Node.js on Lambda (serverless) and Fargate (containerized) Created separate DynamoDB table for Shopping Cart data Applied database-per-service pattern for data independence Eliminated shared database anti-pattern from monolith Achieved autonomous microservice deployment and scaling Implemented Event-Driven Microservices Communication:\nReplaced synchronous REST calls with asynchronous messaging Used Amazon EventBridge for event-driven service communication Implemented pub/sub pattern with SNS and SQS Decoupled microservices eliminating runtime dependencies Improved system resilience (failures don\u0026rsquo;t cascade) Enhanced scalability with asynchronous processing Built Complete CI/CD Pipelines:\nDesigned end-to-end pipeline: CodeCommit ‚Üí CodeBuild ‚Üí CodeDeploy Automated source control with AWS CodeCommit Implemented automated builds, unit tests, and integration tests Deployed applications automatically to staging and production Added manual approval gate before production deployment Achieved continuous delivery with quality gates Adopted DevSecOps Culture:\nIntegrated security testing early in development lifecycle (Shift Left) Added Static Application Security Testing (SAST) in build phase Implemented Dynamic Application Security Testing (DAST) pre-deployment Configured pipeline to fail on critical security vulnerabilities Prevented vulnerable code from reaching production Embedded security into DevOps workflow Deployed Simplified Applications with Elastic Beanstalk:\nDeployed Node.js application using Platform-as-a-Service model Achieved automatic provisioning of EC2, Load Balancer, Auto Scaling Eliminated manual infrastructure configuration Compared Beanstalk simplicity vs ECS/EKS control and flexibility Understood trade-offs: ease of use vs customization Selected appropriate deployment model for different applications Built Enterprise-Grade WordPress Architecture:\nDesigned highly available WordPress with multi-AZ deployment Used Aurora Serverless for automatic database scaling Shared wp-content directory with Amazon EFS across all instances Implemented ElastiCache (Redis) for WordPress object caching Deployed CloudFront CDN for global static content delivery Achieved WordPress scalability handling millions of requests Eliminated single point of failure with redundant architecture Completed Application Modernization Milestone:\nTransformed monolithic applications into microservices architecture Implemented event-driven, loosely-coupled service communication Built automated CI/CD pipelines with security integration Mastered both simplified (Beanstalk) and advanced (microservices) deployment models Achieved DevOps maturity with continuous delivery and security Ready for data analytics and AI/ML challenges Established modern application development and deployment practices "},{"uri":"https://chuong2610.github.io/AWS-Report/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12 Objectives: Master data lake architecture and fundamentals on AWS Build serverless analytics pipelines with AWS Glue and Amazon Athena Create business intelligence dashboards with Amazon QuickSight Learn machine learning fundamentals with Amazon SageMaker Train and tune ML models with built-in algorithms Deploy ML models to production endpoints Integrate AI services for intelligent applications Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 - Learn Data Lake Fundamentals - Practice: + Build data lake on Amazon S3 + Organize data with year/month/day partitioning + Optimize query performance and costs + Store raw, processed, and curated data zones + Implement data lake best practices 11/24/2025 11/24/2025 https://cloudjourney.awsstudygroup.com/ 3 - Learn Serverless Analytics with Glue and Athena - Practice: + Use AWS Glue Crawler to discover data schemas + Automatically create Data Catalog tables + Query S3 data with standard SQL using Athena + Analyze CSV/JSON/Parquet without ETL loading + Build serverless data analytics pipeline 11/25/2025 11/25/2025 https://cloudjourney.awsstudygroup.com/ 4 - Learn Business Intelligence with Amazon QuickSight - Practice: + Connect QuickSight to Athena data source + Create interactive visualizations and charts + Build revenue dashboards by region and time + Embed dashboards in web applications + Share insights with stakeholders 11/26/2025 11/26/2025 https://cloudjourney.awsstudygroup.com/ 5 - Learn Getting Started with Amazon SageMaker - Practice: + Launch SageMaker Studio notebook environment + Import sample datasets and ML projects + Use Data Wrangler for feature engineering + Prepare and transform data with visual interface + Set up complete ML development environment 11/27/2025 11/27/2025 https://cloudjourney.awsstudygroup.com/ 6 - Learn Train and Tune ML Models with XGBoost - Practice: + Select XGBoost built-in algorithm for training + Configure training job with prepared datasets + Use Automatic Model Tuning for hyperparameter optimization + Find best model parameters automatically + Evaluate model accuracy and performance 11/28/2025 11/28/2025 https://cloudjourney.awsstudygroup.com/ 7 - Learn Deploy ML Models to Production - Practice: + Deploy trained model to real-time inference endpoint + Write Python script to send prediction requests + Test model with sample data + Monitor endpoint performance and costs + Delete endpoints to avoid charges 11/29/2025 11/29/2025 https://cloudjourney.awsstudygroup.com/ CN - Learn AWS AI Services Integration - Practice: + Integrate Amazon Rekognition for image recognition + Add face detection and object recognition to applications + Use Amazon Polly for text-to-speech conversion + Implement Amazon Transcribe for speech-to-text + Build intelligent applications without ML expertise 11/30/2025 11/30/2025 https://cloudjourney.awsstudygroup.com/ Week 12 Achievements: Built Data Lake Architecture on AWS:\nDesigned and implemented data lake on Amazon S3 Organized data with hierarchical partitioning (year/month/day/hour) Optimized query performance with partition pruning Reduced costs by scanning only relevant data partitions Created separate zones: Raw, Processed, Curated for data maturity Established foundation for big data analytics and ML Implemented Serverless Analytics Pipeline:\nUsed AWS Glue Crawler for automatic schema discovery Cataloged CSV, JSON, and Parquet data formats automatically Created Data Catalog tables without manual schema definition Queried S3 data directly with Amazon Athena using standard SQL Eliminated ETL jobs and database loading overhead Achieved pay-per-query serverless analytics at scale Created Business Intelligence Dashboards:\nConnected Amazon QuickSight to Athena data sources Built interactive visualizations: bar charts, line graphs, heat maps Created executive dashboards showing revenue by region and time period Implemented drill-down capabilities for detailed analysis Embedded dashboards in web applications for stakeholders Enabled data-driven decision making with self-service BI Established ML Development Environment:\nLaunched Amazon SageMaker Studio for complete ML workflow Imported sample datasets and ML project templates Used SageMaker Data Wrangler for visual feature engineering Performed data cleaning, transformation, and normalization Eliminated complex coding for data preparation tasks Accelerated ML development with integrated notebooks Trained and Optimized ML Models:\nSelected XGBoost built-in algorithm for predictive modeling Configured training jobs with S3 data inputs Implemented Automatic Model Tuning (Hyperparameter Optimization) Explored hundreds of parameter combinations automatically Found optimal model configuration maximizing accuracy Achieved production-ready model performance without manual tuning Deployed ML Models to Production:\nCreated real-time inference endpoints from trained models Deployed scalable, low-latency prediction services Wrote Python scripts using boto3 SDK for predictions Sent sample data to endpoint and received predictions Monitored endpoint latency, throughput, and accuracy Implemented complete ML lifecycle: train ‚Üí tune ‚Üí deploy ‚Üí predict Integrated AI Services for Intelligent Applications:\nImplemented Amazon Rekognition for image and video analysis Added face detection, celebrity recognition, object identification Integrated Amazon Polly for natural text-to-speech conversion Used Amazon Transcribe for automatic speech recognition Built intelligent features without deep ML expertise Accelerated AI adoption with pre-trained, managed services Completed Data \u0026amp; AI/ML Milestone:\nBuilt end-to-end data analytics pipeline from lake to insights Mastered serverless analytics with Glue, Athena, QuickSight Trained, tuned, and deployed machine learning models Integrated AI services for intelligent application features Achieved data-driven and AI-powered application capabilities Completed 3-month comprehensive AWS cloud journey Transitioned from cloud beginner to advanced practitioner Final Journey Summary - 3 Month Transformation:\nMonth 1 (September): Built secure, scalable infrastructure foundation IAM, VPC, EC2, S3, RDS, DynamoDB, Load Balancing, Auto Scaling Month 2 (October): Mastered operations, security, and optimization IaC, Systems Manager, WAF, KMS, GuardDuty, Migration, Cost Optimization Month 3 (November): Achieved modernization with containers, serverless, and AI Docker, ECS, EKS, Lambda, Microservices, CI/CD, Data Lake, ML/AI Total Technical Competencies: 50+ AWS services mastered Architecture Patterns: 10+ production-ready architectures built Certifications Ready: AWS Solutions Architect Associate/Professional Career Outcome: Cloud Engineer/Architect role-ready with enterprise skills "},{"uri":"https://chuong2610.github.io/AWS-Report/content/content/","title":"","tags":[],"description":"","content":" EV Rental AI Agent - H∆∞·ªõng d·∫´n tri·ªÉn khai üìñ T·ªïng quan Gi·ªõi thi·ªáu EV Rental AI Agent l√† m·ªôt chatbot th√¥ng minh ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ h·ªó tr·ª£ kh√°ch h√†ng trong h·ªá th·ªëng cho thu√™ xe ƒëi·ªán VinFast. Agent s·ª≠ d·ª•ng AI ƒë·ªÉ:\nTr·∫£ l·ªùi c√¢u h·ªèi t·ª± nhi√™n b·∫±ng ti·∫øng Vi·ªát T·ª± ƒë·ªông t√¨m ki·∫øm th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn Hi·ªÉn th·ªã d·ªØ li·ªáu d·∫°ng card tr·ª±c quan tr√™n giao di·ªán chat C√¥ng ngh·ªá s·ª≠ d·ª•ng Th√†nh ph·∫ßn C√¥ng ngh·ªá Vai tr√≤ AI Model AWS Bedrock - Claude 3.5 Sonnet X·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n, sinh response Agent Framework Strands Agent SDK T·ª± ƒë·ªông ch·ªçn v√† g·ªçi tools ph√π h·ª£p Backend API FastAPI (Python) REST API server Database PostgreSQL L∆∞u tr·ªØ chat history Frontend React + Chakra UI Giao di·ªán ng∆∞·ªùi d√πng Knowledge Base AWS Bedrock Knowledge Base L∆∞u tr·ªØ t√†i li·ªáu, ch√≠nh s√°ch, FAQ üéØ Ch·ª©c nƒÉng ch√≠nh 1. T√¨m ki·∫øm th√¥ng tin t·ª´ Knowledge Base Kh√°ch h√†ng h·ªèi:\n\u0026ldquo;Ch√≠nh s√°ch thu√™ xe c·ªßa b·∫°n l√† g√¨?\u0026rdquo; \u0026ldquo;Gi√° thu√™ xe VF8 bao nhi√™u?\u0026rdquo; \u0026ldquo;Quy tr√¨nh ƒë·∫∑t xe nh∆∞ th·∫ø n√†o?\u0026rdquo; \u0026ldquo;C√≥ c·∫ßn ƒë·∫∑t c·ªçc kh√¥ng?\u0026rdquo; Agent s·∫Ω:\nT·ª± ƒë·ªông t√¨m ki·∫øm trong Knowledge Base (ch·ª©a t√†i li·ªáu PDF, vƒÉn b·∫£n ch√≠nh s√°ch) T·ªïng h·ª£p th√¥ng tin li√™n quan Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v·ªõi format Markdown V√≠ d·ª• response:\n## üìã Ch√≠nh s√°ch thu√™ xe VinFast ƒê·ªÉ thu√™ xe ƒëi·ªán VinFast, b·∫°n c·∫ßn: ### üìÑ Gi·∫•y t·ªù c·∫ßn thi·∫øt: - ‚úÖ CMND/CCCD g·ªëc (c√≤n hi·ªáu l·ª±c) - ‚úÖ B·∫±ng l√°i xe h·∫°ng B1 tr·ªü l√™n - ‚úÖ H·ªô kh·∫©u ho·∫∑c s·ªï t·∫°m tr√∫ ### üí∞ Chi ph√≠: - **VF8**: 1,500,000 VNƒê/ng√†y - **VF9**: 2,000,000 VNƒê/ng√†y - **ƒê·∫∑t c·ªçc**: 10,000,000 VNƒê ### üìù Quy tr√¨nh: 1. ƒê·∫∑t xe online ho·∫∑c t·∫°i vƒÉn ph√≤ng 2. Cung c·∫•p gi·∫•y t·ªù v√† thanh to√°n 3. K√Ω h·ª£p ƒë·ªìng v√† nh·∫≠n xe 4. Tr·∫£ xe ƒë√∫ng h·∫°n v√† ho√†n c·ªçc 2. Tra c·ª©u xe available Kh√°ch h√†ng h·ªèi:\n\u0026ldquo;Xe n√†o ƒëang c√≥ s·∫µn?\u0026rdquo; \u0026ldquo;T√¨m xe ·ªü H√† N·ªôi t·ª´ 10/12 ƒë·∫øn 15/12\u0026rdquo; \u0026ldquo;VF8 c√≥ s·∫µn kh√¥ng?\u0026rdquo; Agent s·∫Ω:\nG·ªçi API backend l·∫•y danh s√°ch xe L·ªçc theo ti√™u ch√≠ (th√†nh ph·ªë, ng√†y th√°ng, lo·∫°i xe) Hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng Vehicle Cards v·ªõi ƒë·∫ßy ƒë·ªß th√¥ng tin Response format:\n{ \u0026#34;response\u0026#34;: \u0026#34;Hi·ªán c√≥ **3 xe VF8** ƒëang available...\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;vehicles\u0026#34;, \u0026#34;items\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;VF001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;VinFast VF8 Plus\u0026#34;, \u0026#34;model\u0026#34;: \u0026#34;VF8\u0026#34;, \u0026#34;battery_capacity\u0026#34;: 87.7, \u0026#34;range\u0026#34;: 420, \u0026#34;price_per_day\u0026#34;: 1500000, \u0026#34;status\u0026#34;: \u0026#34;available\u0026#34; } ] } } Frontend hi·ªÉn th·ªã:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ üöó VinFast VF8 Plus ‚îÇ ‚îÇ ‚úÖ Available ‚îÇ ‚îÇ ‚ö° 87.7 kWh ‚îÇ ‚îÇ üîã 420 km ‚îÇ ‚îÇ üí∞ 1,500,000 VNƒê/ng√†y ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò 3. T√¨m tr·∫°m s·∫°c g·∫ßn ƒë√¢y Kh√°ch h√†ng h·ªèi:\n\u0026ldquo;C√°c tr·∫°m s·∫°c hi·ªán c√≥\u0026rdquo; \u0026ldquo;Tr·∫°m s·∫°c g·∫ßn t√¥i\u0026rdquo; \u0026ldquo;Tr·∫°m s·∫°c ·ªü H√† N·ªôi\u0026rdquo; Agent s·∫Ω:\nG·ªçi API l·∫•y danh s√°ch tr·∫°m s·∫°c T√≠nh kho·∫£ng c√°ch (n·∫øu c√≥ t·ªça ƒë·ªô) Hi·ªÉn th·ªã Station Cards v·ªõi ƒë·ªãa ch·ªâ, tr·∫°ng th√°i Response format:\n{ \u0026#34;response\u0026#34;: \u0026#34;C√≥ **2 tr·∫°m s·∫°c** g·∫ßn b·∫°n...\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;stations\u0026#34;, \u0026#34;items\u0026#34;: [ { \u0026#34;id\u0026#34;: \u0026#34;ST001\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Tr·∫°m H√† N·ªôi Central\u0026#34;, \u0026#34;address\u0026#34;: \u0026#34;123 L√°ng H·∫°, Ba ƒê√¨nh, H√† N·ªôi\u0026#34;, \u0026#34;status\u0026#34;: \u0026#34;active\u0026#34;, \u0026#34;available_chargers\u0026#34;: 5, \u0026#34;total_chargers\u0026#34;: 8, \u0026#34;distance\u0026#34;: 2.5 } ] } } Frontend hi·ªÉn th·ªã:\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚ö° Tr·∫°m H√† N·ªôi Central ‚îÇ ‚îÇ ‚úÖ ƒêang ho·∫°t ƒë·ªông ‚îÇ ‚îÇ üìç 123 L√°ng H·∫°, Ba ƒê√¨nh ‚îÇ ‚îÇ ‚ö° 5/8 tr·∫°m kh·∫£ d·ª•ng ‚îÇ ‚îÇ üìè C√°ch 2.5 km ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò üèóÔ∏è Ki·∫øn tr√∫c h·ªá th·ªëng ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ React Frontend ‚îÇ ‚Üê User Interface ‚îÇ (Port 3000) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ HTTP POST /chat ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ FastAPI ‚îÇ ‚Üê REST API ‚îÇ (Port 8000) ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚Üì ‚Üì ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇStrands ‚îÇ ‚îÇ PostgreSQL ‚îÇ ‚îÇAgent SDK‚îÇ ‚îÇ (Chat History)‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí AWS Bedrock (Claude 3.5 Sonnet) ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí AWS Bedrock Knowledge Base ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Backend API (Port 8080) ‚îú‚îÄ Vehicles ‚îú‚îÄ Stations ‚îî‚îÄ Bookings üöÄ H∆∞·ªõng d·∫´n tri·ªÉn khai B∆∞·ªõc 1: Chu·∫©n b·ªã m√¥i tr∆∞·ªùng AWS 1.1. T·∫°o AWS Account Truy c·∫≠p: https://aws.amazon.com ƒêƒÉng k√Ω account m·ªõi (c·∫ßn th·∫ª t√≠n d·ª•ng) 1.2. T·∫°o IAM User ƒë·ªÉ s·ª≠ d·ª•ng trong code B∆∞·ªõc 1: T·∫°o IAM User\nV√†o AWS Console ‚Üí IAM ‚Üí Users ‚Üí Create User User name: bedrock-app-user ‚úÖ Ch·ªçn: Provide user access to the AWS Management Console (optional) ‚úÖ Ch·ªçn: I want to create an IAM user Click Next B∆∞·ªõc 2: G√°n quy·ªÅn (Permissions)\nCh·ªçn: Attach policies directly T√¨m v√† ch·ªçn c√°c policies sau: ‚úÖ AmazonBedrockFullAccess - Quy·ªÅn s·ª≠ d·ª•ng Bedrock ‚úÖ (Optional) AmazonS3ReadOnlyAccess - N·∫øu d√πng Knowledge Base v·ªõi S3 Click Next ‚Üí Create User B∆∞·ªõc 3: T·∫°o Access Keys\nClick v√†o user v·ª´a t·∫°o: bedrock-app-user Tab Security credentials Scroll xu·ªëng Access keys ‚Üí Click Create access key Ch·ªçn use case: Application running outside AWS Click Next ‚Üí Create access key ‚ö†Ô∏è QUAN TR·ªåNG: Copy v√† l∆∞u l·∫°i: Access key ID (v√≠ d·ª•: AKIAIOSFODNN7EXAMPLE) Secret access key (ch·ªâ hi·ªÉn th·ªã 1 l·∫ßn, v√≠ d·ª•: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY) Click Done ‚ö†Ô∏è L∆∞u √Ω b·∫£o m·∫≠t:\n# L∆∞u v√†o .env file (KH√îNG commit l√™n Git) AWS_ACCESS_KEY_ID=YOUR_ACCESS_KEY_ID_HERE AWS_SECRET_ACCESS_KEY=YOUR_SECRET_ACCESS_KEY_HERE AWS_REGION=us-west-2 B∆∞·ªõc 2: Setup AWS Bedrock 2.1. Enable Model Access (QUAN TR·ªåNG) L∆∞u √Ω: Ph·∫£i enable model access tr∆∞·ªõc khi s·ª≠ d·ª•ng, n·∫øu kh√¥ng s·∫Ω b·ªã l·ªói ValidationException.\nV√†o AWS Console ‚Üí Services ‚Üí Bedrock ·ªû sidebar b√™n tr√°i, click Model access (·ªü m·ª•c Foundation models) Click n√∫t Manage model access (m√†u cam) T√¨m v√† ch·ªçn c√°c models: ‚úÖ Anthropic - Claude 3.5 Sonnet v2 (anthropic.claude-3-5-sonnet-20241022-v2:0) ‚úÖ Amazon - Titan Embeddings G1 - Text (n·∫øu d√πng Knowledge Base) Click Request model access (·ªü g√≥c d∆∞·ªõi b√™n ph·∫£i) ƒê·ª£i approval: Instant access models: Available ngay l·∫≠p t·ª©c (m√†u xanh ‚úÖ) Other models: Ch·ªù 5-30 ph√∫t (status s·∫Ω ƒë·ªïi t·ª´ \u0026ldquo;In progress\u0026rdquo; ‚Üí \u0026ldquo;Access granted\u0026rdquo;) Ki·ªÉm tra model ƒë√£ enable:\n# D√πng AWS CLI (n·∫øu ƒë√£ c√†i) aws bedrock list-foundation-models --region us-west-2 # Ho·∫∑c check tr√™n Console: # Bedrock ‚Üí Model access ‚Üí Status ph·∫£i l√† \u0026#34;Access granted\u0026#34; 2.2. T·∫°o Knowledge Base (Optional) N·∫øu mu·ªën s·ª≠ d·ª•ng ch·ª©c nƒÉng t√¨m ki·∫øm ch√≠nh s√°ch/FAQ:\nV√†o Bedrock ‚Üí Knowledge Bases ‚Üí Create Ch·ªçn t√™n: ev-rental-knowledge-base Data source: S3 bucket: Upload c√°c file PDF/TXT ch·ª©a: Ch√≠nh s√°ch thu√™ xe B·∫£ng gi√° FAQ Quy tr√¨nh ƒë·∫∑t xe Embeddings model: Titan Embeddings G1 - Text Vector database: Bedrock managed (OpenSearch Serverless) Sync data ‚Üí ƒê·ª£i indexing ho√†n t·∫•t Copy Knowledge Base ID (d·∫°ng 89CI1JSSE4) "},{"uri":"https://chuong2610.github.io/AWS-Report/content/my_info/","title":"","tags":[],"description":"","content":"Tr·∫ßn Ng·ªçc Ch∆∞∆°ng chuongtnse181579@fpt.edu.vn 0397812503 FPT University Software Engineering Internship Company: Amazon Web Services Vietnam Co., Ltd. Internship Position: FCJ Cloud Intern Internship Duration: From 08/09/2025 to 24/12/2025\n"},{"uri":"https://chuong2610.github.io/AWS-Report/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://chuong2610.github.io/AWS-Report/content/","title":"Contents","tags":[],"description":"","content":""},{"uri":"https://chuong2610.github.io/AWS-Report/tags/","title":"Tags","tags":[],"description":"","content":""}]